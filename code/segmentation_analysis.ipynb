{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85c09fe",
   "metadata": {},
   "source": [
    "# Parliamentary Speech Segmentation Analysis\n",
    "\n",
    "This notebook focuses on analyzing parliamentary speech patterns and implementing segmentation algorithms:\n",
    "\n",
    "1. **Data Loading** - Load preprocessed embeddings data\n",
    "2. **Agenda Analysis** - Analyze chairperson speech patterns and agenda keywords\n",
    "3. **Comparative Analysis** - Compare English vs German agenda patterns\n",
    "4. **Segmentation Implementation** - Parliamentary-aware segmentation algorithm\n",
    "5. **Segmentation Evaluation** - Analyze segmentation quality and effectiveness\n",
    "\n",
    "## Key Features:\n",
    "- **Language-specific agenda detection** (English/German)\n",
    "- **Multi-scale similarity analysis** for boundary detection\n",
    "- **Agenda-aware segmentation** prioritizing parliamentary structure\n",
    "- **Comparative keyword analysis** between languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ec8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Load the data with embeddings\n",
    "embeddings = pd.read_pickle(r\"data folder\\data\\AT_with_embeddings_final.pkl\")\n",
    "\n",
    "print(f\"‚úÖ Loaded data: {embeddings.shape}\")\n",
    "print(f\"Columns: {list(embeddings.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bc74f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA OVERVIEW ===\n",
    "print(\"üìä Data Overview:\")\n",
    "print(f\"  ‚Ä¢ Total speeches: {embeddings.shape[0]:,}\")\n",
    "print(f\"  ‚Ä¢ Speech embedding shape: {embeddings['Speech_Embeddings'][0].shape}\")\n",
    "print(f\"  ‚Ä¢ Segment embedding shape: {embeddings['Segment_Embeddings'][0].shape}\")\n",
    "print(f\"  ‚Ä¢ Unique segments: {embeddings['Segment_ID'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per segment: {embeddings.shape[0] / embeddings['Segment_ID'].nunique():.1f}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nüîç Missing values:\")\n",
    "print(f\"  ‚Ä¢ Segment_ID: {embeddings['Segment_ID'].isna().sum()}\")\n",
    "print(f\"  ‚Ä¢ Speech_Embeddings: {embeddings['Speech_Embeddings'].isna().sum()}\")\n",
    "print(f\"  ‚Ä¢ Segment_Embeddings: {embeddings['Segment_Embeddings'].isna().sum()}\")\n",
    "\n",
    "# Check sitting length distribution\n",
    "sitting_lengths = embeddings.groupby('Sitting_ID').size()\n",
    "print(f\"\\nüìà Sitting length distribution:\")\n",
    "print(f\"  ‚Ä¢ Min speeches per sitting: {sitting_lengths.min()}\")\n",
    "print(f\"  ‚Ä¢ Max speeches per sitting: {sitting_lengths.max()}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per sitting: {sitting_lengths.mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Sittings with <50 speeches: {(sitting_lengths < 50).sum()}\")\n",
    "print(f\"  ‚Ä¢ Sittings with >200 speeches: {(sitting_lengths > 200).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COMPREHENSIVE CHAIRPERSON AND AGENDA ANALYSIS ===\n",
    "\n",
    "print(\"üìä Overall Speech Statistics:\")\n",
    "print(f\"  ‚Ä¢ Total speeches in dataset: {len(embeddings):,}\")\n",
    "\n",
    "# Chairperson speeches\n",
    "chairperson_total = embeddings[embeddings['Speaker_role'] == 'Chairperson']\n",
    "print(f\"  ‚Ä¢ Total chairperson speeches: {len(chairperson_total):,}\")\n",
    "print(f\"  ‚Ä¢ Chairperson percentage: {len(chairperson_total)/len(embeddings)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nüìã Agenda-related Speech Analysis:\")\n",
    "\n",
    "# Various agenda patterns\n",
    "agenda_patterns = {\n",
    "    'agenda': embeddings['Text'].str.contains('agenda', case=False),\n",
    "    'agenda item': embeddings['Text'].str.contains('agenda item', case=False),\n",
    "    'next agenda': embeddings['Text'].str.contains('next agenda', case=False),\n",
    "    'next agenda item': embeddings['Text'].str.contains('next agenda item', case=False)\n",
    "}\n",
    "\n",
    "print(\"\\nChairperson speeches only:\")\n",
    "# Count for chairperson speeches only\n",
    "for pattern_name, pattern_mask in agenda_patterns.items():\n",
    "    chairperson_with_pattern = embeddings[(embeddings['Speaker_role'] == 'Chairperson') & pattern_mask]\n",
    "    count = len(chairperson_with_pattern)\n",
    "    percentage_of_chairperson = count / len(chairperson_total) * 100 if len(chairperson_total) > 0 else 0\n",
    "    percentage_of_total = count / len(embeddings) * 100\n",
    "    print(f\"  ‚Ä¢ Containing '{pattern_name}': {count:,} ({percentage_of_chairperson:.1f}% of chairperson speeches, {percentage_of_total:.2f}% of all speeches)\")\n",
    "\n",
    "# Sample analysis\n",
    "chairperson_with_agenda = embeddings[(embeddings['Speaker_role'] == 'Chairperson') & \n",
    "                                    (embeddings['Text'].str.contains('agenda', case=False))]\n",
    "\n",
    "print(f\"\\nüìà Summary of speeches:\")\n",
    "if len(chairperson_with_agenda) > 1:\n",
    "    first_idx = chairperson_with_agenda.index[0]\n",
    "    last_idx = chairperson_with_agenda.index[-1]\n",
    "    total_span = last_idx - first_idx\n",
    "    avg_gap = total_span / (len(chairperson_with_agenda) - 1) if len(chairperson_with_agenda) > 1 else 0\n",
    "    print(f\"  ‚Ä¢ First speech at row: {first_idx:,}\")\n",
    "    print(f\"  ‚Ä¢ Last speech at row: {last_idx:,}\")\n",
    "    print(f\"  ‚Ä¢ Total row span: {total_span:,}\")\n",
    "    print(f\"  ‚Ä¢ Average gap between agenda speeches: {avg_gap:.1f} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load German data for comparison\n",
    "AT_german = pd.read_pickle(r\"data folder\\data\\AT_german.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GERMAN AGENDA ANALYSIS ===\n",
    "\n",
    "print(\"üá©üá™ GERMAN AGENDA ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'Text' in AT_german.columns:\n",
    "    sample_text = AT_german['Text'].iloc[0].lower()\n",
    "    \n",
    "    # Check for German indicators\n",
    "    german_indicators = ['der', 'die', 'das', 'und', 'ist', 'sie', 'haben', 'werden', 'mit', 'tagesordnung']\n",
    "    english_indicators = ['the', 'and', 'is', 'they', 'have', 'will', 'with', 'agenda']\n",
    "    \n",
    "    german_count = sum(1 for word in german_indicators if word in sample_text)\n",
    "    english_count = sum(1 for word in english_indicators if word in sample_text)\n",
    "    \n",
    "    if german_count > english_count:\n",
    "        print(\"‚úÖ German text detected - proceeding with German agenda analysis\")\n",
    "        is_german = True\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è English text detected - German analysis will show zero results\")\n",
    "        is_german = False\n",
    "else:\n",
    "    print(\"‚ùå No 'Text' column found\")\n",
    "    is_german = False\n",
    "\n",
    "if is_german:\n",
    "    print(f\"üìä Overall Speech Statistics:\")\n",
    "    print(f\"  ‚Ä¢ Total speeches in dataset: {len(AT_german):,}\")\n",
    "\n",
    "    # German chairperson speeches (Pr√§sidentIn)\n",
    "    chairperson_total_de = AT_german[AT_german['Speaker_role'] == 'Pr√§sidentIn']\n",
    "    print(f\"  ‚Ä¢ Total Pr√§sidentIn speeches: {len(chairperson_total_de):,}\")\n",
    "    print(f\"  ‚Ä¢ Pr√§sidentIn percentage: {len(chairperson_total_de)/len(AT_german)*100:.1f}%\")\n",
    "\n",
    "    print(\"\\nüìã German Agenda-related Speech Analysis:\")\n",
    "\n",
    "    # German agenda patterns\n",
    "    agenda_patterns_de = {\n",
    "        'tagesordnung': AT_german['Text'].str.contains('tagesordnung', case=False),\n",
    "        'tagesordnungspunkt': AT_german['Text'].str.contains('tagesordnungspunkt', case=False),\n",
    "        'punkt der tagesordnung': AT_german['Text'].str.contains('punkt der tagesordnung', case=False),\n",
    "        'n√§chster tagesordnungspunkt': AT_german['Text'].str.contains('n√§chster tagesordnungspunkt', case=False),\n",
    "        'behandlung': AT_german['Text'].str.contains('behandlung', case=False),\n",
    "        'verhandlung': AT_german['Text'].str.contains('verhandlung', case=False),\n",
    "        'punkt': AT_german['Text'].str.contains('punkt', case=False)\n",
    "    }\n",
    "\n",
    "    print(\"Pr√§sidentIn speeches only:\")\n",
    "    # Count for chairperson speeches only\n",
    "    for pattern_name, pattern_mask in agenda_patterns_de.items():\n",
    "        chairperson_with_pattern = AT_german[(AT_german['Speaker_role'] == 'Pr√§sidentIn') & pattern_mask]\n",
    "        count = len(chairperson_with_pattern)\n",
    "        percentage_of_chairperson = count / len(chairperson_total_de) * 100 if len(chairperson_total_de) > 0 else 0\n",
    "        percentage_of_total = count / len(AT_german) * 100\n",
    "        print(f\"  ‚Ä¢ Containing '{pattern_name}': {count:,} ({percentage_of_chairperson:.1f}% of Pr√§sidentIn speeches, {percentage_of_total:.2f}% of all speeches)\")\n",
    "\n",
    "    print(f\"\\nüìà Summary of German agenda speeches:\")\n",
    "    chairperson_with_tagesordnung = AT_german[(AT_german['Speaker_role'] == 'Pr√§sidentIn') & \n",
    "                                        (AT_german['Text'].str.contains('tagesordnung', case=False))]\n",
    "    if len(chairperson_with_tagesordnung) > 1:\n",
    "        print(f\"  ‚Ä¢ Total Tagesordnung speeches found: {len(chairperson_with_tagesordnung):,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === COMPARATIVE ANALYSIS: ENGLISH vs GERMAN AGENDA PATTERNS ===\n",
    "\n",
    "print(\"üîç COMPARATIVE ANALYSIS: English vs German Agenda Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Based on analysis results - comparing the patterns\n",
    "english_results = {\n",
    "    'agenda': {'count': 11613, 'pct_chair': 9.3, 'pct_total': 5.01},\n",
    "    'agenda item': {'count': 5039, 'pct_chair': 4.0, 'pct_total': 2.17},\n",
    "    'next agenda': {'count': 0, 'pct_chair': 0.0, 'pct_total': 0.00},\n",
    "    'next agenda item': {'count': 0, 'pct_chair': 0.0, 'pct_total': 0.00}\n",
    "}\n",
    "\n",
    "german_results = {\n",
    "    'tagesordnung': {'count': 11779, 'pct_chair': 9.4, 'pct_total': 5.08},\n",
    "    'tagesordnungspunkt': {'count': 2691, 'pct_chair': 2.2, 'pct_total': 1.16},\n",
    "    'punkt der tagesordnung': {'count': 3261, 'pct_chair': 2.6, 'pct_total': 1.41},\n",
    "    'n√§chster tagesordnungspunkt': {'count': 0, 'pct_chair': 0.0, 'pct_total': 0.00},\n",
    "    'behandlung': {'count': 2978, 'pct_chair': 2.4, 'pct_total': 1.28},\n",
    "    'verhandlung': {'count': 9529, 'pct_chair': 7.6, 'pct_total': 4.11},\n",
    "    'punkt': {'count': 13883, 'pct_chair': 11.1, 'pct_total': 5.99}\n",
    "}\n",
    "\n",
    "print(\"üìä Key Findings:\")\n",
    "print(\"\\n1. DIRECT EQUIVALENTS:\")\n",
    "eng_agenda = english_results['agenda']\n",
    "ger_tagesordnung = german_results['tagesordnung']\n",
    "print(f\"   ‚Ä¢ 'agenda' (EN): {eng_agenda['count']:,} speeches ({eng_agenda['pct_chair']:.1f}% of chairperson)\")\n",
    "print(f\"   ‚Ä¢ 'tagesordnung' (DE): {ger_tagesordnung['count']:,} speeches ({ger_tagesordnung['pct_chair']:.1f}% of chairperson)\")\n",
    "print(f\"   ‚Ä¢ Difference: {ger_tagesordnung['count'] - eng_agenda['count']:+,} speeches ({ger_tagesordnung['pct_chair'] - eng_agenda['pct_chair']:+.1f}%)\")\n",
    "\n",
    "print(\"\\n4. SEGMENTATION RECOMMENDATIONS:\")\n",
    "print(\"   üéØ STRONG signals (agenda boundaries):\")\n",
    "print(\"      ‚Ä¢ German: 'tagesordnungspunkt', 'punkt der tagesordnung'\")\n",
    "print(\"      ‚Ä¢ English: 'agenda item'\")\n",
    "print(\"\\n   üéØ MEDIUM signals:\")\n",
    "print(\"      ‚Ä¢ German: 'tagesordnung', 'verhandlung'\")\n",
    "print(\"      ‚Ä¢ English: 'agenda'\")\n",
    "print(\"\\n   ‚ö†Ô∏è  WEAK signals (use carefully):\")\n",
    "print(\"      ‚Ä¢ German: 'behandlung' (removed 'punkt' - too common)\")\n",
    "print(\"      ‚Ä¢ English: limited weak signals\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51e720d",
   "metadata": {},
   "source": [
    "## Parliamentary Segmentation Implementation\n",
    "\n",
    "Enhanced segmentation algorithm that considers parliamentary structure and agenda patterns for both English and German texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parliamentary_segment_speeches(df, window_size=5, min_segment_size=3):\n",
    "    \"\"\"\n",
    "    Parliamentary segmentation with multi-scale analysis and chairperson agenda detection\n",
    "    \"\"\"\n",
    "    segment_ids = []\n",
    "    segmentation_metrics = []\n",
    "    \n",
    "    # Get unique sittings for progress tracking\n",
    "    unique_sittings = df['Sitting_ID'].unique()\n",
    "    print(f\"üîÑ Processing {len(unique_sittings)} sittings...\")\n",
    "    \n",
    "    for sitting_id in tqdm(unique_sittings, desc=\"Segmenting sittings\", unit=\"sitting\"):\n",
    "        group = df[df['Sitting_ID'] == sitting_id]\n",
    "        sitting_length = len(group)\n",
    "        \n",
    "        if sitting_length < min_segment_size:\n",
    "            # Very small sitting - one segment\n",
    "            sitting_segments = [f\"{sitting_id}_seg_0\"] * len(group)\n",
    "            segment_ids.extend(sitting_segments)\n",
    "            segmentation_metrics.append({\n",
    "                'sitting_id': sitting_id,\n",
    "                'sitting_length': sitting_length,\n",
    "                'num_segments': 1,\n",
    "                'avg_segment_size': sitting_length,\n",
    "                'boundaries_found': 0,\n",
    "                'agenda_boundaries': 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        embeddings = np.array(group['Speech_Embeddings'].tolist())\n",
    "        \n",
    "        # Flexible target_segments formula\n",
    "        target_segments = max(2, int(np.ceil(sitting_length / 25)))\n",
    "        threshold_percentile = 40\n",
    "        \n",
    "        # === CHAIRPERSON AGENDA DETECTION ===\n",
    "        agenda_boundaries = set()\n",
    "        agenda_signals = []\n",
    "        \n",
    "        for i, (idx, row) in enumerate(group.iterrows()):\n",
    "            agenda_score = 0\n",
    "            \n",
    "            # Strong signal for chairperson with agenda mentions\n",
    "            if row['Speaker_role'] == 'Chairperson':\n",
    "                text = str(row['Text']).lower()\n",
    "                \n",
    "                if 'agenda item' in text:\n",
    "                    agenda_score = 1.0  # Strongest signal\n",
    "                elif 'agenda' in text:\n",
    "                    agenda_score = 0.7  # Strong signal\n",
    "                elif i == 0:  # First speech by chairperson (session start)\n",
    "                    agenda_score = 0.3  # Mild signal\n",
    "            \n",
    "            agenda_signals.append(agenda_score)\n",
    "            \n",
    "            # Add strong agenda boundaries\n",
    "            if agenda_score >= 0.7 and i >= min_segment_size and (sitting_length - i) >= min_segment_size:\n",
    "                agenda_boundaries.add(i)\n",
    "        \n",
    "        # === MULTI-SCALE SIMILARITY ANALYSIS ===\n",
    "        # ...existing similarity analysis code...\n",
    "        \n",
    "        # === BOUNDARY DETECTION AND ASSIGNMENT ===\n",
    "        # ...existing boundary detection code...\n",
    "        \n",
    "        # Store metrics\n",
    "        segmentation_metrics.append({\n",
    "            'sitting_id': sitting_id,\n",
    "            'sitting_length': sitting_length,\n",
    "            'num_segments': len(set(sitting_segments)),\n",
    "            'avg_segment_size': sitting_length / len(set(sitting_segments)),\n",
    "            'boundaries_found': len(boundaries) if 'boundaries' in locals() else 0,\n",
    "            'agenda_boundaries': len([b for b in boundaries if b in agenda_boundaries]) if 'boundaries' in locals() else 0\n",
    "        })\n",
    "    \n",
    "    df['Segment_ID'] = segment_ids\n",
    "    return df, segmentation_metrics\n",
    "\n",
    "print(\"‚úÖ Parliamentary segmentation function loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b42b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === APPLY PARLIAMENTARY SEGMENTATION ===\n",
    "print(\"üèõÔ∏è Running Parliamentary Segmentation...\")\n",
    "\n",
    "# Check data size first\n",
    "long_speeches_df = embeddings[~embeddings['Is_Too_Short']].copy()\n",
    "unique_sittings = long_speeches_df['Sitting_ID'].nunique()\n",
    "total_speeches = len(long_speeches_df)\n",
    "\n",
    "print(f\"üìä Data to process:\")\n",
    "print(f\"  ‚Ä¢ Unique sittings: {unique_sittings:,}\")\n",
    "print(f\"  ‚Ä¢ Total speeches: {total_speeches:,}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per sitting: {total_speeches/unique_sittings:.1f}\")\n",
    "\n",
    "# Run parliamentary segmentation\n",
    "segmented_df, seg_metrics = parliamentary_segment_speeches(\n",
    "    long_speeches_df, \n",
    "    window_size=5,        \n",
    "    min_segment_size=3\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Parliamentary segmentation complete!\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"  ‚Ä¢ Total speeches processed: {len(segmented_df):,}\")\n",
    "print(f\"  ‚Ä¢ Unique segments created: {segmented_df['Segment_ID'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per segment: {len(segmented_df) / segmented_df['Segment_ID'].nunique():.1f}\")\n",
    "\n",
    "# Convert metrics to DataFrame for analysis\n",
    "metrics_df = pd.DataFrame(seg_metrics)\n",
    "\n",
    "print(f\"\\nüìà Segmentation Quality Overview:\")\n",
    "print(f\"  ‚Ä¢ Average segments per sitting: {metrics_df['num_segments'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Average segment size: {metrics_df['avg_segment_size'].mean():.1f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
