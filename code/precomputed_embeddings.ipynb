{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e08b95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded data: (231752, 30)\n",
      "Columns: ['Sitting_ID', 'Speech_ID', 'Title', 'Date', 'Body', 'Term', 'Session', 'Meeting', 'Sitting', 'Agenda', 'Subcorpus', 'Lang', 'Speaker_role', 'Speaker_MP', 'Speaker_minister', 'Speaker_party', 'Speaker_party_name', 'Party_status', 'Party_orientation', 'Speaker_ID', 'Speaker_name', 'Speaker_gender', 'Speaker_birth', 'Text', 'Word_Count', 'Is_Too_Short', 'Is_Filtered', 'Speech_Embeddings', 'Segment_ID', 'Segment_Embeddings']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# Load the data with embeddings (already segmented)\n",
    "embeddings = pd.read_pickle(r\"data folder\\data\\AT_with_embeddings_final.pkl\")\n",
    "\n",
    "print(f\"‚úÖ Loaded data: {embeddings.shape}\")\n",
    "print(f\"Columns: {list(embeddings.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737eceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Data Overview:\n",
      "  ‚Ä¢ Total speeches: 231,752\n",
      "  ‚Ä¢ Speech embedding shape: (1024,)\n",
      "  ‚Ä¢ Segment embedding shape: (1024,)\n",
      "  ‚Ä¢ Unique segments: 5,728\n",
      "  ‚Ä¢ Average speeches per segment: 40.5\n",
      "\n",
      "üîç Missing values:\n",
      "  ‚Ä¢ Segment_ID: 0\n",
      "  ‚Ä¢ Speech_Embeddings: 41119\n",
      "  ‚Ä¢ Segment_Embeddings: 0\n",
      "\n",
      "üìà Sitting length distribution:\n",
      "  ‚Ä¢ Min speeches per sitting: 1\n",
      "  ‚Ä¢ Max speeches per sitting: 1378\n",
      "  ‚Ä¢ Average speeches per sitting: 189.8\n",
      "  ‚Ä¢ Sittings with <50 speeches: 474\n",
      "  ‚Ä¢ Sittings with >200 speeches: 542\n",
      "  ‚Ä¢ Segment_Embeddings: 0\n",
      "\n",
      "üìà Sitting length distribution:\n",
      "  ‚Ä¢ Min speeches per sitting: 1\n",
      "  ‚Ä¢ Max speeches per sitting: 1378\n",
      "  ‚Ä¢ Average speeches per sitting: 189.8\n",
      "  ‚Ä¢ Sittings with <50 speeches: 474\n",
      "  ‚Ä¢ Sittings with >200 speeches: 542\n"
     ]
    }
   ],
   "source": [
    "# === DATA OVERVIEW ===\n",
    "print(\"üìä Data Overview:\")\n",
    "print(f\"  ‚Ä¢ Total speeches: {embeddings.shape[0]:,}\")\n",
    "print(f\"  ‚Ä¢ Speech embedding shape: {embeddings['Speech_Embeddings'][0].shape}\")\n",
    "print(f\"  ‚Ä¢ Segment embedding shape: {embeddings['Segment_Embeddings'][0].shape}\")\n",
    "print(f\"  ‚Ä¢ Unique segments: {embeddings['Segment_ID'].nunique():,}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per segment: {embeddings.shape[0] / embeddings['Segment_ID'].nunique():.1f}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nüîç Missing values:\")\n",
    "print(f\"  ‚Ä¢ Segment_ID: {embeddings['Segment_ID'].isna().sum()}\")\n",
    "print(f\"  ‚Ä¢ Speech_Embeddings: {embeddings['Speech_Embeddings'].isna().sum()}\")\n",
    "print(f\"  ‚Ä¢ Segment_Embeddings: {embeddings['Segment_Embeddings'].isna().sum()}\")\n",
    "\n",
    "# Check sitting length distribution\n",
    "sitting_lengths = embeddings.groupby('Sitting_ID').size()\n",
    "print(f\"\\nüìà Sitting length distribution:\")\n",
    "print(f\"  ‚Ä¢ Min speeches per sitting: {sitting_lengths.min()}\")\n",
    "print(f\"  ‚Ä¢ Max speeches per sitting: {sitting_lengths.max()}\")\n",
    "print(f\"  ‚Ä¢ Average speeches per sitting: {sitting_lengths.mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Sittings with <50 speeches: {(sitting_lengths < 50).sum()}\")\n",
    "print(f\"  ‚Ä¢ Sittings with >200 speeches: {(sitting_lengths > 200).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d46b6c",
   "metadata": {},
   "source": [
    "## Topic Modeling with BERTopic\n",
    "\n",
    "This notebook focuses on topic modeling using pre-segmented parliamentary speeches. The data has already been processed with:\n",
    "- Speech-level embeddings for similarity analysis\n",
    "- Segment-level embeddings for topic modeling\n",
    "- Parliamentary-aware segmentation with agenda detection\n",
    "\n",
    "We'll implement hierarchical BERTopic with LLM classification to map topics to 22 policy categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e4a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BERTOPIC SETUP WITH GUIDED TOPICS ===\n",
    "from bertopic import BERTopic\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "from umap import UMAP\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Define the 22 target topic categories\n",
    "label_list = [\n",
    "    \"Education\", \"Technology\", \"Health\", \"Environment\", \"Housing\", \"Labor\", \n",
    "    \"Defense\", \"Government Operations\", \"Social Welfare\", \"Other\", \"Macroeconomics\", \n",
    "    \"Domestic Commerce\", \"Civil Rights\", \"International Affairs\", \"Transportation\", \n",
    "    \"Immigration\", \"Law and Crime\", \"Agriculture\", \"Foreign Trade\", \"Culture\", \n",
    "    \"Public Lands\", \"Energy\"\n",
    "]\n",
    "\n",
    "# Detailed topic descriptions for better classification\n",
    "majortopics_description = {\n",
    "    'Macroeconomics': 'issues related to domestic macroeconomic policy, such as the state and prospect of the national economy, economic policy, inflation, interest rates, monetary policy, cost of living, unemployment rate, national budget, public debt, price control, tax enforcement, industrial revitalization and growth.',\n",
    "    'Civil Rights': 'issues related to civil rights and minority rights, discrimination towards races, gender, sexual orientation, handicap, and other minorities, voting rights, freedom of speech, religious freedoms, privacy rights, protection of personal data, abortion rights, anti-government activity groups (e.g., local insurgency groups), religion and the Church.',\n",
    "    'Health': 'issues related to health care, health care reforms, health insurance, drug industry, medical facilities, medical workers, disease prevention, treatment, and health promotion, drug and alcohol abuse, mental health, research in medicine, medical liability and unfair medical practices.',\n",
    "    'Agriculture': 'issues related to agriculture policy, fishing, agricultural foreign trade, food marketing, subsidies to farmers, food inspection and safety, animal and crop disease, pest control and pesticide regulation, welfare for animals in farms, pets, veterinary medicine, agricultural research.',\n",
    "    'Labor': 'issues related to labor, employment, employment programs, employee benefits, pensions and retirement accounts, minimum wage, labor law, job training, labor unions, worker safety and protection, youth employment and seasonal workers.',\n",
    "    'Education': 'issues related to educational policies, primary and secondary schools, student loans and education finance, the regulation of colleges and universities, school reforms, teachers, vocational training, evening schools, safety in schools, efforts to improve educational standards, and issues related to libraries, dictionaries, teaching material, research in education.',\n",
    "    'Environment': 'issues related to environmental policy, drinking water safety, all kinds of pollution (air, noise, soil), waste disposal, recycling, climate change, outdoor environmental hazards (e.g., asbestos), species and forest protection, marine and freshwater environment, hunting, regulation of laboratory or performance animals, land and water resource conservation, research in environmental technology.',\n",
    "    'Energy': 'issues related to energy policy, electricity, regulation of electrical utilities, nuclear energy and disposal of nuclear waste, natural gas and oil, drilling, oil spills, oil and gas prices, heat supply, shortages and gasoline regulation, coal production, alternative and renewable energy, energy conservation and energy efficiency, energy research.',\n",
    "    'Immigration': 'issues related to immigration, refugees, and citizenship, integration issues, regulation of residence permits, asylum applications; criminal offences and diseases caused by immigration.',\n",
    "    'Transportation': 'issues related to mass transportation construction and regulation, bus transport, regulation related to motor vehicles, road construction, maintenance and safety, parking facilities, traffic accidents statistics, air travel, rail travel, rail freight, maritime transportation, inland waterways and channels, transportation research and development.',\n",
    "    'Law and Crime': 'issues related to the control, prevention, and impact of crime; all law enforcement agencies, including border and customs, police, court system, prison system; terrorism, white collar crime, counterfeiting and fraud, cyber-crime, drug trafficking, domestic violence, child welfare, family law, juvenile crime.',\n",
    "    'Social Welfare': 'issues related to social welfare policy, the Ministry of Social Affairs, social services, poverty assistance for low-income families and for the elderly, parental leave and child care, assistance for people with physical or mental disabilities, including early retirement pension, discounts on public services, volunteer associations (e.g., Red Cross), charities, and youth organizations.',\n",
    "    'Housing': 'issues related to housing, urban affairs and community development, housing market, property tax, spatial planning, rural development, location permits, construction inspection, illegal construction, industrial and commercial building issues, national housing policy, housing for low-income individuals, rental housing, housing for the elderly, e.g., nursing homes, housing for the homeless and efforts to reduce homelessness, research related to housing.',\n",
    "    'Domestic Commerce': 'issues related to banking, finance and internal commerce, including stock exchange, investments, consumer finance, mortgages, credit cards, insurance availability and cost, accounting regulation, personal, commercial, and municipal bankruptcies, programs to promote small businesses, copyrights and patents, intellectual property, natural disaster preparedness and relief, consumer safety; regulation and promotion of tourism, sports, gambling, and personal fitness; domestic commerce research.',\n",
    "    'Defense': 'issues related to defense policy, military intelligence, espionage, weapons, military personnel, reserve forces, military buildings, military courts, nuclear weapons, civil defense, including firefighters and mountain rescue services, homeland security, military aid or arms sales to other countries, prisoners of war and collateral damage to civilian populations, military nuclear and hazardous waste disposal and military environmental compliance, defense alliances and agreements, direct foreign military operations, claims against military, defense research.',\n",
    "    'Technology': 'issues related to science and technology transfer and international science cooperation, research policy, government space programs and space exploration, telephones and telecommunication regulation, broadcast media (television, radio, newspapers, films), weather forecasting, geological surveys, computer industry, cyber security.',\n",
    "    'Foreign Trade': 'issues related to foreign trade, trade negotiations, free trade agreements, import regulation, export promotion and regulation, subsidies, private business investment and corporate development, competitiveness, exchange rates, the strength of national currency in comparison to other currencies, foreign investment and sales of companies abroad.',\n",
    "    'International Affairs': 'issues related to international affairs, foreign policy and relations to other countries, issues related to the Ministry of Foreign Affairs, foreign aid, international agreements (such as Kyoto agreement on the environment, the Schengen agreement), international organizations (including United Nations, UNESCO, International Olympic Committee, International Criminal Court), NGOs, issues related to diplomacy, embassies, citizens abroad; issues related to border control; issues related to international finance, including the World Bank and International Monetary Fund, the financial situation of the EU; issues related to a foreign country that do not impact the home country; issues related to human rights in other countries, international terrorism.',\n",
    "    'Government Operations': 'issues related to general government operations, the work of multiple departments, public employees, postal services, nominations and appointments, national mints, medals, and commemorative coins, management of government property, government procurement and contractors, public scandal and impeachment, claims against the government, the state inspectorate and audit, anti-corruption policies, regulation of political campaigns, political advertising and voter registration, census and statistics collection by government; issues related to local government, capital city and municipalities, including decentralization; issues related to national holidays.',\n",
    "    'Public Lands': 'issues related to national parks, memorials, historic sites, and protected areas, including the management and staffing of cultural sites; museums; use of public lands and forests, establishment and management of harbors and marinas; issues related to flood control, forest fires, livestock grazing.',\n",
    "    'Culture': 'issues related to cultural policies, Ministry of Culture, public spending on culture, cultural employees, issues related to support of theatres and artists; allocation of funds from the national lottery, issues related to cultural heritage.',\n",
    "    'Other': 'other topics not mentioning policy agendas, including the procedures of parliamentary meetings, e.g., points of order, voting procedures, meeting logistics; interpersonal speech, e.g., greetings, personal stories, tributes, interjections, arguments between the members; rhetorical speech, e.g., jokes, literary references.'\n",
    "}\n",
    "\n",
    "# Austrian parliament-specific stop words\n",
    "custom_stopwords = [\n",
    "    'mr', 'mrs', 'ms', 'dr', 'madam', 'honourable', 'member', 'members', 'vp', 'sp', 'fp', \n",
    "    'minister', 'speaker', 'deputy', 'president', 'chairman', 'chair', 'schilling', \n",
    "    'secretary', 'lord', 'lady', 'question', 'order', 'point', 'debate', 'motion', 'amendment',\n",
    "    'congratulations', 'congratulate', 'thanks', 'thank', 'say', 'one', 'want', 'know', 'think', \n",
    "    'believe', 'see', 'go', 'come', 'give', 'take', 'people', 'federal', 'government', 'austria', \n",
    "    'austrian', 'committee', 'call', 'said', 'already', 'please', 'request', 'proceed', 'reading',\n",
    "    'course', 'welcome', 'council', 'open', 'written', 'contain', 'items', 'item', 'yes', 'no', \n",
    "    'following', 'next', 'speech', 'year', 'years', 'state', 'also', 'would', 'like', 'may', 'must', \n",
    "    'upon', 'indeed', 'session', 'meeting', 'report', 'commission', 'behalf', 'gentleman', 'gentlemen', \n",
    "    'ladies', 'applause', 'group', 'colleague', 'colleagues', 'issue', 'issues', 'chancellor', 'court', \n",
    "    'ask', 'answer', 'reply', 'regard', 'regarding', 'regards', 'respect', 'respectfully', 'sign', \n",
    "    'shall', 'procedure', 'declare', 'hear', 'minutes', 'speaking', 'close', 'abg', 'mag', 'orf', 'wait'\n",
    "]\n",
    "\n",
    "all_stopwords = list(ENGLISH_STOP_WORDS) + custom_stopwords\n",
    "\n",
    "# Prepare segment data for topic modeling  \n",
    "segment_texts = embeddings.groupby('Segment_ID')['Text'].apply(lambda x: ' '.join(x)).tolist()\n",
    "segment_embeddings = np.array(embeddings.groupby('Segment_ID')['Segment_Embeddings'].first().tolist())\n",
    "\n",
    "# Configure vectorizer\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=all_stopwords,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    max_df=0.9,\n",
    "    max_features=1000\n",
    ")\n",
    "\n",
    "print(f\"üéØ Target categories: {len(label_list)} topics\")\n",
    "print(f\"üìä Topic modeling data prepared:\")\n",
    "print(f\"  ‚Ä¢ Segments for modeling: {len(segment_texts)}\")\n",
    "print(f\"  ‚Ä¢ Embedding dimension: {segment_embeddings.shape[1]}\")\n",
    "print(f\"üìñ Topic descriptions loaded for enhanced classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HIERARCHICAL BERTOPIC (RECOMMENDED APPROACH) ===\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "def train_hierarchical_bertopic():\n",
    "    \"\"\"Train BERTopic with many subtopics, then map to 22 main categories.\"\"\"\n",
    "    print(\"üèóÔ∏è Training Hierarchical BERTopic with HDBSCAN...\")\n",
    "    \n",
    "    # Configure UMAP and HDBSCAN for more granular topics\n",
    "    umap_model = UMAP(n_neighbors=10, n_components=8, metric='cosine', random_state=42)\n",
    "    \n",
    "    # Use HDBSCAN to find clusters automatically.\n",
    "    # A smaller min_cluster_size will result in more, smaller topics.\n",
    "    clustering_model = HDBSCAN(\n",
    "        min_cluster_size=5,\n",
    "        metric='euclidean',\n",
    "        cluster_selection_method='eom',\n",
    "        prediction_data=True\n",
    "    )\n",
    "    \n",
    "    representation_model = KeyBERTInspired()\n",
    "    \n",
    "    topic_model_hierarchical = BERTopic(\n",
    "        embedding_model=\"all-MiniLM-L6-v2\",\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=clustering_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        representation_model=representation_model,\n",
    "        min_topic_size=10,  # Align with min_cluster_size\n",
    "        calculate_probabilities=True,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    topics, probs = topic_model_hierarchical.fit_transform(segment_texts, embeddings=segment_embeddings)\n",
    "    topic_info_hierarchical = topic_model_hierarchical.get_topic_info()\n",
    "    \n",
    "    print(f\"‚úÖ Hierarchical model created {len(topic_info_hierarchical[topic_info_hierarchical['Topic'] != -1])} subtopics\")\n",
    "    \n",
    "    return topic_model_hierarchical, topics, topic_info_hierarchical\n",
    "\n",
    "# Train hierarchical model\n",
    "topic_model_hierarchical, topics_hierarchical, topic_info_hierarchical = train_hierarchical_bertopic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09505f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e80a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLM CLASSIFICATION TO 22 CATEGORIES ===\n",
    "\n",
    "# Load environment variables\n",
    "dotenv_path = os.path.join(os.pardir, '.env')\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path)\n",
    "    print(f\"‚úÖ Loaded .env file from: {dotenv_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è .env file not found. Ensure OPENAI_API_KEY is set in environment.\")\n",
    "\n",
    "def classify_topic_to_22_categories(topic_words, topic_id=-1):\n",
    "    \"\"\"Enhanced classification using detailed topic descriptions.\"\"\"\n",
    "    if not isinstance(topic_words, list) or not topic_words:\n",
    "        return \"Other\"\n",
    "    \n",
    "    keywords_str = ', '.join(topic_words[:12])  # Use top 12 words for better context\n",
    "    \n",
    "    # Create detailed category descriptions for the prompt\n",
    "    category_descriptions = []\n",
    "    for category in label_list:\n",
    "        description = majortopics_description.get(category, f\"Issues related to {category.lower()}\")\n",
    "        category_descriptions.append(f\"‚Ä¢ {category}: {description}\")\n",
    "    \n",
    "    categories_text = '\\n'.join(category_descriptions)\n",
    "    \n",
    "    prompt = f\"\"\"You are analyzing topics from parliamentary debates. \n",
    "\n",
    "TOPIC KEYWORDS: {keywords_str}\n",
    "\n",
    "AVAILABLE CATEGORIES WITH DESCRIPTIONS:\n",
    "{categories_text}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Analyze the keywords carefully in the context of parliamentary discussions\n",
    "2. Consider which category description best matches the semantic content of the keywords\n",
    "3. Look for key thematic indicators (e.g., \"economic\", \"health\", \"defense\", \"education\", etc.)\n",
    "4. If keywords relate to parliamentary procedures, interpersonal speech, or don't fit policy areas, choose \"Other\"\n",
    "5. Choose the single best-fitting category\n",
    "\n",
    "RESPONSE: Only output the exact category name from the list above.\"\"\"\n",
    "\n",
    "    try:\n",
    "        if not os.getenv('OPENAI_API_KEY'):\n",
    "            print(f\"Error: OPENAI_API_KEY not set for topic {topic_id}\")\n",
    "            return \"Other\"\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in political science, parliamentary procedures, and policy classification. You excel at accurately mapping topic keywords to policy domains.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.05,  # Very low temperature for consistency\n",
    "            max_tokens=30\n",
    "        )\n",
    "        \n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Clean the response and ensure exact match\n",
    "        classification = classification.replace('\"', '').replace(\"'\", \"\").strip()\n",
    "        \n",
    "        # Exact match check\n",
    "        if classification in label_list:\n",
    "            return classification\n",
    "        \n",
    "        # Fuzzy matching for partial matches\n",
    "        classification_lower = classification.lower()\n",
    "        for category in label_list:\n",
    "            if category.lower() == classification_lower:\n",
    "                return category\n",
    "            # Check if classification contains the category name\n",
    "            if category.lower() in classification_lower or classification_lower in category.lower():\n",
    "                return category\n",
    "                \n",
    "        # Special handling for common variations\n",
    "        category_mapping = {\n",
    "            'macro': 'Macroeconomics',\n",
    "            'economics': 'Macroeconomics', \n",
    "            'economic': 'Macroeeconomics',\n",
    "            'rights': 'Civil Rights',\n",
    "            'welfare': 'Social Welfare',\n",
    "            'social': 'Social Welfare',\n",
    "            'crime': 'Law and Crime',\n",
    "            'legal': 'Law and Crime',\n",
    "            'justice': 'Law and Crime',\n",
    "            'foreign': 'International Affairs',\n",
    "            'international': 'International Affairs',\n",
    "            'trade': 'Foreign Trade',\n",
    "            'government': 'Government Operations',\n",
    "            'administration': 'Government Operations'\n",
    "        }\n",
    "        \n",
    "        for key, mapped_category in category_mapping.items():\n",
    "            if key in classification_lower:\n",
    "                return mapped_category\n",
    "        \n",
    "        return \"Other\"  # Final fallback\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying topic {topic_id}: {e}\")\n",
    "        return \"Other\"\n",
    "\n",
    "def map_topics_to_22_categories(topic_info, approach_name):\n",
    "    \"\"\"Map topics to the 22 predefined categories using LLM classification.\"\"\"\n",
    "    print(f\"ü§ñ Classifying {approach_name} topics into 22 categories...\")\n",
    "    \n",
    "    topic_info_classified = topic_info.copy()\n",
    "    topic_info_classified['Category_22'] = \"Other\"\n",
    "    \n",
    "    classification_results = []\n",
    "    \n",
    "    for idx, row in topic_info_classified.iterrows():\n",
    "        if row['Topic'] != -1:\n",
    "            topic_words = row['Representation']\n",
    "            classification = classify_topic_to_22_categories(topic_words, row['Topic'])\n",
    "            topic_info_classified.loc[idx, 'Category_22'] = classification\n",
    "            \n",
    "            classification_results.append({\n",
    "                'Topic_ID': row['Topic'],\n",
    "                'Keywords': ', '.join(topic_words[:5]),\n",
    "                'Classification': classification,\n",
    "                'Count': row['Count']\n",
    "            })\n",
    "    \n",
    "    # Count topics per category\n",
    "    category_counts = topic_info_classified[topic_info_classified['Topic'] != -1]['Category_22'].value_counts()\n",
    "    \n",
    "    print(f\"\\nüìä {approach_name} - Classification results:\")\n",
    "    for category in label_list:\n",
    "        count = category_counts.get(category, 0)\n",
    "        if count > 0:\n",
    "            topic_count = len(classification_results)\n",
    "            percentage = (count / topic_count * 100) if topic_count > 0 else 0\n",
    "            print(f\"  ‚Ä¢ {category:<20}: {count:>2} topics ({percentage:>5.1f}%)\")\n",
    "    \n",
    "    return topic_info_classified\n",
    "\n",
    "# Apply LLM classification\n",
    "print(\"üöÄ Applying LLM classification to map subtopics to 22 categories...\")\n",
    "topic_info_classified = map_topics_to_22_categories(topic_info_hierarchical, \"Hierarchical BERTopic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CREATE FINAL 22-TOPIC MAPPING ===\n",
    "\n",
    "def create_final_22_topic_mapping():\n",
    "    \"\"\"Create final mapping to 22 topics.\"\"\"\n",
    "    print(\"üèóÔ∏è Creating final 22-topic mapping...\")\n",
    "    \n",
    "    # Create segment-level mapping\n",
    "    segment_topic_map = pd.DataFrame({\n",
    "        'Segment_ID': segmented_df['Segment_ID'].unique(),\n",
    "        'Subtopic_ID': topics_hierarchical,\n",
    "    })\n",
    "    \n",
    "    # Map subtopics to 22 categories\n",
    "    subtopic_to_category = dict(zip(\n",
    "        topic_info_classified['Topic'], \n",
    "        topic_info_classified['Category_22']\n",
    "    ))\n",
    "    \n",
    "    segment_topic_map['Topic_22'] = segment_topic_map['Subtopic_ID'].map(subtopic_to_category)\n",
    "    segment_topic_map['Topic_22'] = segment_topic_map['Topic_22'].fillna('Other')\n",
    "    \n",
    "    # Merge with original data\n",
    "    embeddings_with_22_topics = segmented_df.merge(\n",
    "        segment_topic_map, \n",
    "        on='Segment_ID', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Generate topic statistics\n",
    "    category_stats = embeddings_with_22_topics.groupby('Topic_22').agg({\n",
    "        'Segment_ID': 'nunique',\n",
    "        'Text': 'count'\n",
    "    }).rename(columns={\n",
    "        'Segment_ID': 'Unique_Segments',\n",
    "        'Text': 'Total_Speeches'\n",
    "    }).sort_values('Total_Speeches', ascending=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Final 22-topic mapping created!\")\n",
    "    print(f\"üìä Topic distribution:\")\n",
    "    for topic, stats in category_stats.iterrows():\n",
    "        print(f\"  ‚Ä¢ {topic:<20}: {stats['Total_Speeches']:>4} speeches, {stats['Unique_Segments']:>3} segments\")\n",
    "    \n",
    "    return embeddings_with_22_topics, topic_info_classified, category_stats\n",
    "\n",
    "# Create final mapping\n",
    "final_embeddings, final_topic_info, category_stats = create_final_22_topic_mapping()\n",
    "\n",
    "print(f\"\\nüéâ SUCCESS: Mapped all topics to 22 predefined categories!\")\n",
    "print(f\"üìà Coverage: {len(category_stats)} out of {len(label_list)} categories have content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b85629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FINAL RESULTS ===\n",
    "\n",
    "# Display final topic information\n",
    "print(\"üìã Final Topic Classifications:\")\n",
    "final_display = final_topic_info[final_topic_info['Topic'] != -1][['Topic', 'Count', 'Category_22', 'Representation']].copy()\n",
    "final_display['Keywords'] = final_display['Representation'].apply(lambda x: ', '.join(x[:5]))\n",
    "final_display = final_display.drop('Representation', axis=1).sort_values('Count', ascending=False)\n",
    "\n",
    "print(final_display.head(15).to_string(index=False))\n",
    "\n",
    "# Show category coverage\n",
    "print(f\"\\nüìä Category Coverage Summary:\")\n",
    "print(f\"Categories with content: {len(category_stats)}/{len(label_list)}\")\n",
    "print(f\"Most common categories:\")\n",
    "for category, stats in category_stats.head(10).iterrows():\n",
    "    percentage = (stats['Total_Speeches'] / final_embeddings.shape[0] * 100)\n",
    "    print(f\"  ‚Ä¢ {category:<20}: {percentage:>5.1f}% of speeches\")\n",
    "\n",
    "# Find and display categories with no content\n",
    "represented_categories = set(category_stats.index)\n",
    "unrepresented_categories = set(label_list) - represented_categories\n",
    "\n",
    "if unrepresented_categories:\n",
    "    print(f\"\\nCategories with no content (0% of speeches):\")\n",
    "    for category in sorted(list(unrepresented_categories)):\n",
    "        print(f\"  ‚Ä¢ {category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f955d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE RESULTS (OPTIONAL) ===\n",
    "# Uncomment to save the final results\n",
    "\n",
    "# print(\"üíæ Saving final results...\")\n",
    "# final_embeddings.to_pickle('data folder/data/AT_with_22_topics_final.pkl')\n",
    "# final_topic_info.to_pickle('data folder/data/topic_info_22_categories.pkl')\n",
    "# category_stats.to_pickle('data folder/data/category_statistics.pkl')\n",
    "# print(\"‚úÖ Results saved!\")\n",
    "\n",
    "print(\"\\nüéâ Analysis complete! Ready to run.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
