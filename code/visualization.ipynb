{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb917d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 11,\n",
    "    'figure.titlesize': 14\n",
    "})\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Output directory\n",
    "output_dir = r\"C:\\Users\\pavle\\OneDrive\\Desktop\\my github\\master-thesis\\figures\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6068ceae",
   "metadata": {},
   "source": [
    "# PART 1: Topic Classification Evaluation\n",
    "\n",
    "Evaluating our topic classification against ParlaCAP predictions and human labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = r\"data folder\"\n",
    "\n",
    "GB = pd.read_pickle(os.path.join(BASE_DATA_DIR, \"GB/GB_final.pkl\"))\n",
    "AT = pd.read_pickle(os.path.join(BASE_DATA_DIR, \"AT/AT_final.pkl\"))\n",
    "HR = pd.read_pickle(os.path.join(BASE_DATA_DIR, \"HR/HR_final.pkl\"))\n",
    "\n",
    "print(f\"   AT={AT.shape}, HR={HR.shape}, GB={GB.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c98823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HR['topic_consensus'].value_counts()\n",
    "\n",
    "HR['CAP_Category_HR_croatian'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea88a56",
   "metadata": {},
   "source": [
    "## Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7175fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_labels(df, evaluation_col, true_label_col, sample_size='all', min_word_count=None,\n",
    "                   exclude_roles=None, exclude_topics=None, text_column='Text_English', \n",
    "                   plot_size=(16, 12), dataset_name=\"Dataset\"):\n",
    "    \"\"\"Generate confusion matrix and metrics\"\"\"\n",
    "    \n",
    "    exclude_roles = exclude_roles or []\n",
    "    exclude_topics = exclude_topics or []\n",
    "    \n",
    "    # Filter\n",
    "    df = df[~df[true_label_col].isin(['-'])].dropna(subset=[evaluation_col, true_label_col])\n",
    "    \n",
    "    if exclude_roles:\n",
    "        df = df[~df['Speaker_role'].isin(exclude_roles)]\n",
    "    if exclude_topics:\n",
    "        df = df[~df[evaluation_col].isin(exclude_topics)]\n",
    "        df = df[~df[true_label_col].isin(exclude_topics)]\n",
    "    if min_word_count:\n",
    "        df = df[df[text_column].apply(lambda x: len(str(x).split())) >= min_word_count]\n",
    "    \n",
    "    # Sample\n",
    "    if sample_size != 'all':\n",
    "        sampled = []\n",
    "        for cat in df[true_label_col].unique():\n",
    "            cat_df = df[df[true_label_col] == cat]\n",
    "            sampled.append(cat_df.sample(n=min(sample_size, len(cat_df))))\n",
    "        df = pd.concat(sampled, ignore_index=True)\n",
    "    \n",
    "    # Metrics\n",
    "    y_true = df[true_label_col]\n",
    "    y_pred = df[evaluation_col]\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=plot_size)\n",
    "    categories = y_true.value_counts().index.tolist()\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=categories)\n",
    "    sns.heatmap(conf_matrix, xticklabels=categories, yticklabels=categories, annot=True, \n",
    "                fmt='d', cmap='Blues', square=True, annot_kws={'size': 8})\n",
    "    plt.title(f'{dataset_name}: F1 macro={f1_macro:.2f}, micro={f1_micro:.2f}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'confusion_{dataset_name.lower()}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {'f1_macro': f1_macro, 'f1_micro': f1_micro, 'total': len(df)}\n",
    "\n",
    "# Run analysis\n",
    "results = {}\n",
    "results['GB'] = analyze_labels(GB, 'topic_consensus', 'True_label', exclude_topics=['Mix'], dataset_name=\"GB\")\n",
    "results['HR'] = analyze_labels(HR, 'topic_consensus', 'True_label', exclude_topics=['Mix'], dataset_name=\"HR\")\n",
    "results['AT'] = analyze_labels(AT, 'topic_consensus', 'Topic', exclude_topics=['Mix'], \n",
    "                               min_word_count=70, dataset_name=\"AT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b37ae29",
   "metadata": {},
   "source": [
    "## Topic Distribution Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5fdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_topic_distributions(df, our_col, comparison_col, dataset_name, exclude_topics=['Other', 'Mix']):\n",
    "    \"\"\"Compare topic distributions\"\"\"\n",
    "    clean = df.dropna(subset=[our_col, comparison_col])\n",
    "    for topic in exclude_topics:\n",
    "        clean = clean[(clean[our_col] != topic) & (clean[comparison_col] != topic)]\n",
    "    \n",
    "    # Check if we have enough data after filtering\n",
    "    if len(clean) == 0:\n",
    "        print(f\"⚠️ Warning: {dataset_name} has no overlapping topics after filtering {exclude_topics}\")\n",
    "        return\n",
    "    \n",
    "    our_dist = clean[our_col].value_counts(normalize=True) * 100\n",
    "    comp_dist = clean[comparison_col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    # Check if we have any topics to compare\n",
    "    if len(our_dist) == 0 or len(comp_dist) == 0:\n",
    "        print(f\"⚠️ Warning: {dataset_name} has no topics to compare after filtering\")\n",
    "        return\n",
    "    \n",
    "    comparison = pd.DataFrame({'Our': our_dist, 'Reference': comp_dist}).fillna(0)\n",
    "    \n",
    "    # Check if comparison has any rows\n",
    "    if len(comparison) == 0:\n",
    "        print(f\"⚠️ Warning: {dataset_name} comparison dataframe is empty\")\n",
    "        return\n",
    "    \n",
    "    diff = (comparison['Our'] - comparison['Reference']).reindex(\n",
    "        (comparison['Our'] - comparison['Reference']).abs().sort_values(ascending=True).index)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    \n",
    "    comparison.plot(kind='barh', ax=ax1, width=0.8, alpha=0.8)\n",
    "    ax1.set_title(f'{dataset_name}: Topic Distribution Comparison')\n",
    "    ax1.set_xlabel('Percentage (%)')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    colors = ['red' if x < 0 else 'green' for x in diff]\n",
    "    diff.plot(kind='barh', ax=ax2, color=colors, alpha=0.7)\n",
    "    ax2.set_title(f'{dataset_name}: Difference (Our - Reference)')\n",
    "    ax2.set_xlabel('Percentage Point Difference')\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'dist_{dataset_name.lower()}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "compare_topic_distributions(GB, 'topic_consensus', 'True_label', 'GB')\n",
    "compare_topic_distributions(HR, 'topic_consensus', 'True_label', 'HR')\n",
    "compare_topic_distributions(AT, 'topic_consensus', 'Topic', 'AT')\n",
    "\n",
    "print(\"✅ Topic classification evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771eac5a",
   "metadata": {},
   "source": [
    "---\n",
    "# PART 2: LIWC Linguistic Analysis\n",
    "\n",
    "Analyzing political discourse using LIWC-22 dimensions across countries, topics, and covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c95b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LIWC benchmarks\n",
    "LIWC_statistics_path = r\"data folder\\LIWC-22.Descriptive.Statistics-Test.Kitchen.xlsx\"\n",
    "\n",
    "def load_liwc_benchmarks(file_path):\n",
    "    \"\"\"Load LIWC-22 population norms\"\"\"\n",
    "    raw = pd.read_excel(file_path, sheet_name=0, header=None)\n",
    "    header_row = raw.iloc[0]\n",
    "    total_col_start = [i for i, v in enumerate(header_row) if str(v).strip() == 'Total'][0]\n",
    "    \n",
    "    dimensions = raw.iloc[2:, 0].dropna().reset_index(drop=True)\n",
    "    means = pd.to_numeric(raw.iloc[2:2+len(dimensions), total_col_start], errors='coerce')\n",
    "    stds = pd.to_numeric(raw.iloc[2:2+len(dimensions), total_col_start+1], errors='coerce')\n",
    "    \n",
    "    return pd.DataFrame({'Dimension': dimensions, 'Mean': means.values, 'Std': stds.values}).dropna()\n",
    "\n",
    "LIWC_benchmarks = load_liwc_benchmarks(LIWC_statistics_path)\n",
    "\n",
    "# Combine datasets for analysis\n",
    "LIWC_ALL = pd.concat([AT, HR, GB], ignore_index=True)\n",
    "\n",
    "# Rename for consistency\n",
    "LIWC_ALL.rename(columns={'topic_consensus': 'Our_Topic', 'Topic': 'ParlaCAP'}, inplace=True)\n",
    "\n",
    "# Filter out non-policy content\n",
    "LIWC_ALL = LIWC_ALL[~LIWC_ALL['Our_Topic'].isin(['Mix', 'Other'])]\n",
    "LIWC_ALL = LIWC_ALL[LIWC_ALL['Speaker_role'] != 'Chairperson']\n",
    "\n",
    "# Key dimensions\n",
    "KEY_LIWC_DIMENSIONS = [\n",
    "    'Analytic', 'Clout', 'Authentic', 'Tone',\n",
    "    'i', 'we', 'you', 'they', 'ipron', 'ppron',\n",
    "    'focuspast', 'focuspresent', 'focusfuture',\n",
    "    'cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certitude',\n",
    "    'Affect', 'tone_pos', 'tone_neg',\n",
    "    'Social', 'conflict', 'moral',\n",
    "    'power', 'politic', 'money', 'work'\n",
    "]\n",
    "\n",
    "print(f\"✅ LIWC analysis ready: {len(LIWC_ALL):,} speeches\")\n",
    "print(f\"   Countries: {LIWC_ALL['Country'].unique().tolist()}\")\n",
    "print(f\"   Key dimensions: {len(KEY_LIWC_DIMENSIONS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd7d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_heatmap(data, benchmarks, dimensions):\n",
    "    \"\"\"Z-score heatmap with categorical groupings and labels\"\"\"\n",
    "    country_means = data.groupby('Country')[dimensions].mean()\n",
    "    overall_means = data[dimensions].mean()\n",
    "    country_means.loc['All Countries'] = overall_means\n",
    "    \n",
    "    benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "    z_scores = (country_means - benchmark_lookup.loc[dimensions, 'Mean']) / benchmark_lookup.loc[dimensions, 'Std']\n",
    "    \n",
    "    # Define groups exactly as in your image\n",
    "    summary_vars = ['Analytic', 'Clout', 'Authentic', 'Tone']\n",
    "    \n",
    "    # Personal Pronouns group\n",
    "    pronoun_vars = ['i', 'we', 'you', 'shehe', 'they', 'ipron', 'ppron']\n",
    "    pronoun_vars = [v for v in pronoun_vars if v in dimensions]\n",
    "    \n",
    "    # Time Orientation group\n",
    "    temporal_vars = ['focuspast', 'focuspresent', 'focusfuture']\n",
    "    temporal_vars = [v for v in temporal_vars if v in dimensions]\n",
    "    \n",
    "    # Cognitive Processes group\n",
    "    cognitive_vars = ['cogproc', 'insight', 'cause', 'discrep', 'tentat', 'certitude']\n",
    "    cognitive_vars = [v for v in cognitive_vars if v in dimensions]\n",
    "    \n",
    "    # Emotion group\n",
    "    affect_vars = ['Affect', 'tone_pos', 'tone_neg']\n",
    "    affect_vars = [v for v in affect_vars if v in dimensions]\n",
    "    \n",
    "    # Social group\n",
    "    social_vars = ['Social', 'conflict', 'moral']\n",
    "    social_vars = [v for v in social_vars if v in dimensions]\n",
    "    \n",
    "    # Power & Politics group\n",
    "    political_vars = ['power', 'politic', 'money', 'work']\n",
    "    political_vars = [v for v in political_vars if v in dimensions]\n",
    "    \n",
    "    # Build ordered list\n",
    "    ordered_dims = []\n",
    "    category_labels = []\n",
    "    separator_positions = []\n",
    "    \n",
    "    # Add Summary Variables\n",
    "    ordered_dims.extend(summary_vars)\n",
    "    category_labels.append(('Summary\\nVariables', 0, len(summary_vars)))\n",
    "    separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Personal Pronouns\n",
    "    if pronoun_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(pronoun_vars)\n",
    "        category_labels.append(('Personal\\nPronouns', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Time Orientation\n",
    "    if temporal_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(temporal_vars)\n",
    "        category_labels.append(('Time\\nOrientation', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Cognitive Processes\n",
    "    if cognitive_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(cognitive_vars)\n",
    "        category_labels.append(('Cognitive\\nProcesses', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Emotion\n",
    "    if affect_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(affect_vars)\n",
    "        category_labels.append(('Emotion', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Social\n",
    "    if social_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(social_vars)\n",
    "        category_labels.append(('Social', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    # Add Power & Politics\n",
    "    if political_vars:\n",
    "        start_pos = len(ordered_dims)\n",
    "        ordered_dims.extend(political_vars)\n",
    "        category_labels.append(('Power\\n&\\nPolitics', start_pos, len(ordered_dims)))\n",
    "        separator_positions.append(len(ordered_dims))\n",
    "    \n",
    "    z_scores_ordered = z_scores[ordered_dims].T\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 20))\n",
    "    sns.heatmap(z_scores_ordered, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0, \n",
    "                cbar_kws={'label': 'Z-Score (from population norm)'}, vmin=-2, vmax=2, ax=ax, square=False)\n",
    "    \n",
    "    # Add separator lines\n",
    "    for pos in separator_positions[:-1]:\n",
    "        ax.axhline(y=pos, color='black', linewidth=2)\n",
    "    \n",
    "    # Add category labels on the left\n",
    "    for label_text, start, end in category_labels:\n",
    "        y_pos = (start + end) / 2\n",
    "        ax.text(-0.5, y_pos, label_text, \n",
    "                fontsize=11, fontweight='bold', color='darkblue',\n",
    "                verticalalignment='center', horizontalalignment='right')\n",
    "    \n",
    "    ax.set_title(\"Political Discourse: LIWC Z-Scores vs. Population Norms\\n(All KEY_LIWC_DIMENSIONS)\", \n",
    "                 fontweight='bold', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'liwc_country_zscores.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "create_country_heatmap(LIWC_ALL, LIWC_benchmarks, KEY_LIWC_DIMENSIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ceb577",
   "metadata": {},
   "source": [
    "## Topic-LIWC Interaction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a92223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_topic_liwc_heatmap(data, benchmarks, topic_col='Our_Topic', \n",
    "                               top_n_topics=8):\n",
    "    \"\"\"Create topic-LIWC interaction heatmap for each country\"\"\"\n",
    "    \n",
    "    # Fixed dimensions (always first 5)\n",
    "    fixed_dims = ['Analytic', 'Clout', 'Authentic', 'Tone', 'power']\n",
    "    \n",
    "    # Get top topics by frequency\n",
    "    top_topics = data[topic_col].value_counts().head(top_n_topics).index.tolist()\n",
    "    filtered_data = data[data[topic_col].isin(top_topics)].copy()\n",
    "    \n",
    "    # Z-score normalize all KEY_LIWC_DIMENSIONS\n",
    "    benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "    for dim in KEY_LIWC_DIMENSIONS:\n",
    "        if dim in benchmark_lookup.index:\n",
    "            mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "            std = benchmark_lookup.loc[dim, 'Std']\n",
    "            filtered_data[f'{dim}_z'] = (filtered_data[dim] - mean) / std\n",
    "    \n",
    "    countries = ['Austria', 'Croatia', 'Great Britain']\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(24, 12))\n",
    "    \n",
    "    for idx, country in enumerate(countries):\n",
    "        country_data = filtered_data[filtered_data['Country'] == country]\n",
    "        \n",
    "        # Calculate z-scores by topic for all dimensions\n",
    "        z_cols = [f'{d}_z' for d in KEY_LIWC_DIMENSIONS if f'{d}_z' in country_data.columns]\n",
    "        topic_means = country_data.groupby(topic_col)[z_cols].mean()\n",
    "        \n",
    "        # Calculate average absolute z-score for each dimension (excluding fixed)\n",
    "        other_cols = [c for c in topic_means.columns if c.replace('_z', '') not in fixed_dims]\n",
    "        avg_abs_z = topic_means[other_cols].abs().mean(axis=0).sort_values(ascending=False)\n",
    "        top_5_other = avg_abs_z.head(5).index.tolist()\n",
    "        \n",
    "        # Combine fixed + top 5 by z-score\n",
    "        selected_cols = [f'{d}_z' for d in fixed_dims] + top_5_other\n",
    "        topic_means_selected = topic_means[selected_cols]\n",
    "        topic_means_selected.columns = [c.replace('_z', '') for c in topic_means_selected.columns]\n",
    "        \n",
    "        # Order topics by frequency\n",
    "        topic_order = country_data[topic_col].value_counts().index\n",
    "        topic_means_selected = topic_means_selected.reindex(topic_order)\n",
    "        \n",
    "        # Transpose for dimensions as rows\n",
    "        topic_means_T = topic_means_selected.T\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[idx]\n",
    "        sns.heatmap(topic_means_T, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "                   center=0, vmin=-1.5, vmax=1.5, ax=ax, \n",
    "                   cbar_kws={'label': 'Z-Score'}, square=False)\n",
    "        \n",
    "        # Add separator line after first 5 dimensions\n",
    "        ax.axhline(y=5, color='black', linewidth=2)\n",
    "        \n",
    "        ax.set_title(country, fontweight='bold', fontsize=14)\n",
    "        ax.set_xlabel('Policy Topic', fontweight='bold')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('LIWC Dimension', fontweight='bold')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        \n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    fig.suptitle('Topic-LIWC Interaction: Linguistic Style by Policy Domain and Country', \n",
    "                 fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'topic_liwc_interaction.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "create_topic_liwc_heatmap(LIWC_ALL, LIWC_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_focal_topic_analysis(data, benchmarks, focal_topics):\n",
    "    \"\"\"Compare focal topics vs all other topics with dynamic top 5 selection\"\"\"\n",
    "    \n",
    "    # Fixed dimensions (always first 5)\n",
    "    fixed_dims = ['Analytic', 'Authentic', 'Clout', 'Tone', 'power']\n",
    "    \n",
    "    countries = ['Austria', 'Croatia', 'Great Britain', 'All Countries']\n",
    "    \n",
    "    # First pass: calculate all z-score differences to determine top 5\n",
    "    all_diffs = []\n",
    "    for focal_topic in focal_topics:\n",
    "        for country in countries:\n",
    "            if country == 'All Countries':\n",
    "                country_data = data.copy()\n",
    "            else:\n",
    "                country_data = data[data['Country'] == country].copy()\n",
    "            \n",
    "            focal_data = country_data[country_data['Our_Topic'] == focal_topic]\n",
    "            other_data = country_data[country_data['Our_Topic'] != focal_topic]\n",
    "            \n",
    "            benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "            for dim in KEY_LIWC_DIMENSIONS:\n",
    "                if dim in benchmark_lookup.index and dim not in fixed_dims:\n",
    "                    mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "                    std = benchmark_lookup.loc[dim, 'Std']\n",
    "                    \n",
    "                    focal_z = (focal_data[dim].mean() - mean) / std\n",
    "                    other_z = (other_data[dim].mean() - mean) / std\n",
    "                    diff = abs(focal_z - other_z)\n",
    "                    all_diffs.append({'dimension': dim, 'diff': diff})\n",
    "    \n",
    "    # Get top 5 dimensions by average absolute difference\n",
    "    diff_df = pd.DataFrame(all_diffs)\n",
    "    top_5_other = diff_df.groupby('dimension')['diff'].mean().nlargest(5).index.tolist()\n",
    "    selected_dims = fixed_dims + top_5_other\n",
    "    \n",
    "    # Second pass: calculate results with selected dimensions\n",
    "    results = {}\n",
    "    for focal_topic in focal_topics:\n",
    "        topic_results = []\n",
    "        \n",
    "        for country in countries:\n",
    "            if country == 'All Countries':\n",
    "                country_data = data.copy()\n",
    "            else:\n",
    "                country_data = data[data['Country'] == country].copy()\n",
    "            \n",
    "            focal_data = country_data[country_data['Our_Topic'] == focal_topic]\n",
    "            other_data = country_data[country_data['Our_Topic'] != focal_topic]\n",
    "            \n",
    "            benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "            diffs = {}\n",
    "            for dim in selected_dims:\n",
    "                if dim in benchmark_lookup.index:\n",
    "                    mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "                    std = benchmark_lookup.loc[dim, 'Std']\n",
    "                    \n",
    "                    focal_z = (focal_data[dim].mean() - mean) / std\n",
    "                    other_z = (other_data[dim].mean() - mean) / std\n",
    "                    diffs[dim] = focal_z - other_z\n",
    "            \n",
    "            topic_results.append(diffs)\n",
    "        \n",
    "        results[focal_topic] = pd.DataFrame(topic_results, index=countries).T\n",
    "    \n",
    "    # Create subplots\n",
    "    n_topics = len(focal_topics)\n",
    "    fig, axes = plt.subplots(1, n_topics, figsize=(12 * n_topics, 8))\n",
    "    if n_topics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, focal_topic in enumerate(focal_topics):\n",
    "        ax = axes[idx]\n",
    "        data_to_plot = results[focal_topic]\n",
    "        \n",
    "        sns.heatmap(data_to_plot, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "                   center=0, vmin=-1, vmax=1, ax=ax, square=False,\n",
    "                   cbar_kws={'label': f'Z-Score Difference (Focal Topic - Other)'})\n",
    "        \n",
    "        # Add separator line after first 5 dimensions\n",
    "        ax.axhline(y=5, color='black', linewidth=2)\n",
    "        \n",
    "        ax.set_title(f'{focal_topic} vs Other Topics', fontweight='bold', fontsize=13)\n",
    "        ax.set_xlabel('')\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('LIWC Dimension', fontweight='bold')\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "    \n",
    "    fig.suptitle('Focal Topics Analysis: Linguistic Differences', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'focal_topics_analysis.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "create_focal_topic_analysis(LIWC_ALL, LIWC_benchmarks, \n",
    "                            focal_topics=['Macroeconomics', 'Health'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc70b15",
   "metadata": {},
   "source": [
    "## Political Covariates Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_covariate_heatmap_with_counts(data, benchmarks, covariate_col, categories, \n",
    "                                         dimensions, title, filename, order_by_effect=False):\n",
    "    \"\"\"Covariate heatmap with sample sizes in labels\"\"\"\n",
    "    filtered = data[data[covariate_col].isin(categories)].copy()\n",
    "    \n",
    "    # Get sample sizes\n",
    "    sample_sizes = filtered[covariate_col].value_counts()\n",
    "    \n",
    "    # Z-score normalize\n",
    "    benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "    for dim in dimensions:\n",
    "        if dim in benchmark_lookup.index:\n",
    "            mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "            std = benchmark_lookup.loc[dim, 'Std']\n",
    "            filtered[f'{dim}_z'] = (filtered[dim] - mean) / std\n",
    "    \n",
    "    means = filtered.groupby(covariate_col)[[f'{d}_z' for d in dimensions]].mean()\n",
    "    means.columns = [c.replace('_z', '') for c in means.columns]\n",
    "    \n",
    "    # Order by effect size if requested\n",
    "    if order_by_effect and len(categories) == 2:\n",
    "        diff = (means.iloc[0] - means.iloc[1]).abs().sort_values(ascending=False)\n",
    "        means = means[diff.index]\n",
    "    \n",
    "    # Add horizontal line after first group (summary variables + top effect)\n",
    "    separator_position = None\n",
    "    if 'power' in means.columns:\n",
    "        separator_position = list(means.columns).index('power') + 1\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(means.T, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "                vmin=-1, vmax=1, ax=ax, square=False,\n",
    "                cbar_kws={'label': 'Z-Score Diff (Coalition - Opposition)' if 'Coalition' in categories \n",
    "                         else 'Z-Score Diff (Female - Male)' if 'F' in categories\n",
    "                         else 'Z-Score'})\n",
    "    \n",
    "    # Add separator line\n",
    "    if separator_position:\n",
    "        ax.axhline(y=separator_position, color='black', linewidth=2)\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    \n",
    "    # Update column labels with sample sizes\n",
    "    col_labels = [f\"{cat}\\n(N={sample_sizes[cat]:,})\" for cat in means.index]\n",
    "    ax.set_xticklabels(col_labels, rotation=0)\n",
    "    \n",
    "    # Add total sample size info at bottom\n",
    "    total_n = sum(sample_sizes)\n",
    "    coalition_n = sample_sizes.get('Coalition', 0)\n",
    "    opp_n = sample_sizes.get('Opposition', 0)\n",
    "    \n",
    "    if coalition_n and opp_n:\n",
    "        bottom_text = f\"(Coal={coalition_n:,}, Opp={opp_n:,})\"\n",
    "        fig.text(0.5, -0.02, bottom_text, ha='center', fontsize=10)\n",
    "    elif 'F' in sample_sizes.index and 'M' in sample_sizes.index:\n",
    "        f_n = sample_sizes['F']\n",
    "        m_n = sample_sizes['M']\n",
    "        bottom_text = f\"(F={f_n:,}, M={m_n:,})\"\n",
    "        fig.text(0.5, -0.02, bottom_text, ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def create_country_split_heatmap(data, benchmarks, covariate_col, categories, \n",
    "                                 dimensions, title, filename):\n",
    "    \"\"\"Create side-by-side heatmaps for each country with 10 dimensions (5 fixed + top 5 by effect)\"\"\"\n",
    "    countries = ['Austria', 'Croatia', 'Great Britain', 'All Countries']\n",
    "    \n",
    "    # Fixed dimensions (always first 5)\n",
    "    fixed_dims = ['Analytic', 'Clout', 'Authentic', 'Tone', 'power']\n",
    "    \n",
    "    results = []\n",
    "    for country in countries:\n",
    "        if country == 'All Countries':\n",
    "            country_data = data.copy()\n",
    "        else:\n",
    "            country_data = data[data['Country'] == country].copy()\n",
    "        \n",
    "        filtered = country_data[country_data[covariate_col].isin(categories)].copy()\n",
    "        \n",
    "        # Z-score normalize\n",
    "        benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "        for dim in dimensions:\n",
    "            if dim in benchmark_lookup.index:\n",
    "                mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "                std = benchmark_lookup.loc[dim, 'Std']\n",
    "                filtered[f'{dim}_z'] = (filtered[dim] - mean) / std\n",
    "        \n",
    "        means = filtered.groupby(covariate_col)[[f'{d}_z' for d in dimensions]].mean()\n",
    "        means.columns = [c.replace('_z', '') for c in means.columns]\n",
    "        \n",
    "        # Calculate difference\n",
    "        if len(categories) == 2:\n",
    "            diff = means.iloc[0] - means.iloc[1]\n",
    "            results.append(diff)\n",
    "   \n",
    "    # Create dataframe with all countries\n",
    "    all_results = pd.DataFrame(results, index=countries).T\n",
    "    \n",
    "    # Order by absolute difference and select top 5 non-fixed dimensions\n",
    "    non_fixed_dims = [d for d in all_results.index if d not in fixed_dims]\n",
    "    avg_abs = all_results.loc[non_fixed_dims].abs().mean(axis=1).sort_values(ascending=False)\n",
    "    top_5_other = avg_abs.head(5).index.tolist()\n",
    "    \n",
    "    # Combine fixed + top 5\n",
    "    selected_dims = fixed_dims + top_5_other\n",
    "    all_results = all_results.loc[selected_dims]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(all_results, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "                vmin=-1, vmax=1, ax=ax, square=False,\n",
    "                cbar_kws={'label': 'Z-Score Diff (Coalition - Opposition)' if categories[0] == 'Coalition'\n",
    "                         else 'Z-Score Diff (Female - Male)'})\n",
    "    \n",
    "    # Add separator line after first 5 dimensions\n",
    "    ax.axhline(y=5, color='black', linewidth=2)\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Coalition vs Opposition - 10 dimensions with separator\n",
    "create_country_split_heatmap(LIWC_ALL, LIWC_benchmarks, 'Party_status', \n",
    "                             ['Coalition', 'Opposition'], KEY_LIWC_DIMENSIONS,\n",
    "                             'Coalition vs Opposition: Top 10 Linguistic Differences', \n",
    "                             'liwc_party_status.png')\n",
    "\n",
    "# Gender Differences - 10 dimensions with separator\n",
    "create_country_split_heatmap(LIWC_ALL, LIWC_benchmarks, 'Speaker_gender', \n",
    "                             ['M', 'F'], KEY_LIWC_DIMENSIONS,\n",
    "                             'Gender Differences: Top 10 Linguistic Dimensions', \n",
    "                             'liwc_gender.png')\n",
    "\n",
    "# Political Orientation (Left-Right spectrum)\n",
    "def create_political_orientation_heatmap(data, benchmarks, dimensions):\n",
    "    \"\"\"Create political orientation heatmap\"\"\"\n",
    "    # Define political orientation categories\n",
    "    orientation_map = {\n",
    "        'Left': ['N='],  # Add your left parties\n",
    "        'Centre-left': [],\n",
    "        'Centre': [],\n",
    "        'Centre-right': [],\n",
    "        'Right': []\n",
    "    }\n",
    "    \n",
    "    # Filter data with political orientation\n",
    "    filtered = data.dropna(subset=['Party_name']).copy()\n",
    "    \n",
    "    # Z-score normalize\n",
    "    benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "    for dim in dimensions:\n",
    "        if dim in benchmark_lookup.index:\n",
    "            mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "            std = benchmark_lookup.loc[dim, 'Std']\n",
    "            filtered[f'{dim}_z'] = (filtered[dim] - mean) / std\n",
    "    \n",
    "    # Group by party and calculate means\n",
    "    party_means = filtered.groupby('Party_name')[[f'{d}_z' for d in dimensions]].mean()\n",
    "    party_means.columns = [c.replace('_z', '') for c in party_means.columns]\n",
    "    \n",
    "    # Get sample sizes\n",
    "    party_counts = filtered['Party_name'].value_counts()\n",
    "    \n",
    "    # Select key dimensions for display\n",
    "    display_dims = ['Analytic', 'Authentic', 'Clout', 'Tone', 'power', \n",
    "                   'moral', 'politic', 'ipron', 'cogproc', 'you']\n",
    "    party_means = party_means[display_dims]\n",
    "    \n",
    "    # Sort by sample size\n",
    "    party_means = party_means.loc[party_counts.index]\n",
    "    \n",
    "    # Create labels with sample sizes\n",
    "    party_labels = [f\"{party}\\n(N={party_counts[party]:,})\" \n",
    "                   for party in party_means.index]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 10))\n",
    "    sns.heatmap(party_means.T, annot=True, fmt='.2f', cmap='RdBu_r', \n",
    "               center=0, vmin=-2, vmax=2, ax=ax, square=False,\n",
    "               cbar_kws={'label': 'Z-Score'})\n",
    "    \n",
    "    ax.set_xticklabels(party_labels, rotation=45, ha='right')\n",
    "    ax.set_title('Political Orientation Differences: Linguistic Dimensions\\n(Left to Right spectrum)', \n",
    "                fontweight='bold', fontsize=14)\n",
    "    ax.set_xlabel('Political Orientation', fontweight='bold')\n",
    "    ax.set_ylabel('LIWC Dimension', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'political_orientation.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Age Groups\n",
    "if 'Speaker_age' in LIWC_ALL.columns:\n",
    "    age_data = LIWC_ALL.dropna(subset=['Speaker_age']).copy()\n",
    "    age_data['Age_Group'] = pd.cut(age_data['Speaker_age'], \n",
    "                                     bins=[0, 35, 50, 65, 100], \n",
    "                                     labels=['<35', '35-50', '51-65', '66+'])\n",
    "    \n",
    "    age_dims = ['Analytic', 'Authentic', 'Clout', 'Tone', 'power', \n",
    "                'ipron', 'politic', 'certitude', 'money', 'Social']\n",
    "    \n",
    "    # Get sample sizes\n",
    "    age_counts = age_data['Age_Group'].value_counts()\n",
    "    \n",
    "    # Z-score and group\n",
    "    benchmark_lookup = LIWC_benchmarks.set_index('Dimension')\n",
    "    for dim in age_dims:\n",
    "        if dim in benchmark_lookup.index:\n",
    "            mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "            std = benchmark_lookup.loc[dim, 'Std']\n",
    "            age_data[f'{dim}_z'] = (age_data[dim] - mean) / std\n",
    "    \n",
    "    means = age_data.groupby('Age_Group')[[f'{d}_z' for d in age_dims]].mean()\n",
    "    means.columns = [c.replace('_z', '') for c in means.columns]\n",
    "    \n",
    "    # Create labels with sample sizes\n",
    "    age_labels = [f\"{age}\\n(N={age_counts[age]:,})\" for age in means.index]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(means.T, annot=True, fmt='.2f', cmap='RdBu_r', center=0, \n",
    "                vmin=-2, vmax=2, ax=ax, square=False,\n",
    "                cbar_kws={'label': 'Z-Score'})\n",
    "    \n",
    "    # Add separator line after first 5 dimensions\n",
    "    ax.axhline(y=5, color='black', linewidth=2)\n",
    "    \n",
    "    ax.set_xticklabels(age_labels, rotation=0)\n",
    "    ax.set_title('Age Group Differences: Linguistic Dimensions', fontweight='bold')\n",
    "    ax.set_xlabel('Age Group', fontweight='bold')\n",
    "    ax.set_ylabel('LIWC Dimension', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'liwc_age_groups.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"✅ All covariate analyses complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c725068a",
   "metadata": {},
   "source": [
    "## Temporal Evolution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_plot(data, benchmarks, dimensions, countries, title, filename, add_events=True):\n",
    "    \"\"\"Temporal evolution with shared x-axis, background shading, and event markers\"\"\"\n",
    "    benchmark_lookup = benchmarks.set_index('Dimension')\n",
    "    temporal_data = data[data['Date'].notna()].copy()\n",
    "    \n",
    "    for dim in dimensions:\n",
    "        mean = benchmark_lookup.loc[dim, 'Mean']\n",
    "        std = benchmark_lookup.loc[dim, 'Std']\n",
    "        temporal_data[f'{dim}_z'] = (temporal_data[dim] - mean) / std\n",
    "    \n",
    "    # Determine overall date range from all countries\n",
    "    min_date = temporal_data['Date'].min()\n",
    "    max_date = temporal_data['Date'].max()\n",
    "    \n",
    "    # Key events to annotate\n",
    "    events = {\n",
    "        'Austria': [\n",
    "            ('2008-09-15', 'Financial\\nCrisis'),\n",
    "            ('2015-09-01', 'Refugee\\nCrisis'),\n",
    "            ('2020-03-16', 'COVID-19'),\n",
    "            ('2022-02-24', 'Ukraine\\nWar')\n",
    "        ],\n",
    "        'Croatia': [\n",
    "            ('2008-09-15', 'Financial\\nCrisis'),\n",
    "            ('2013-07-01', 'EU\\nAccession'),\n",
    "            ('2015-09-01', 'Refugee\\nCrisis'),\n",
    "            ('2020-03-16', 'COVID-19'),\n",
    "            ('2022-02-24', 'Ukraine\\nWar')\n",
    "        ],\n",
    "        'Great Britain': [\n",
    "            ('2016-06-23', 'Brexit\\nVote'),\n",
    "            ('2020-01-31', 'Brexit'),\n",
    "            ('2020-03-23', 'COVID-19'),\n",
    "            ('2022-02-24', 'Ukraine\\nWar')\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Political periods - simplified to 2 colors alternating at elections\n",
    "    periods = {\n",
    "        'Austria': [\n",
    "            ('1996-01-01', '2000-02-04', '#8DB4E2'),  # Color 1\n",
    "            ('2000-02-04', '2007-01-11', '#C4D79B'),  # Color 2 (election)\n",
    "            ('2007-01-11', '2017-12-18', '#8DB4E2'),  # Color 1 (election)\n",
    "            ('2017-12-18', '2019-06-03', '#C4D79B'),  # Color 2 (election)\n",
    "            ('2019-06-03', '2020-01-07', '#8DB4E2'),  # Color 1 (election)\n",
    "            ('2020-01-07', '2022-12-31', '#C4D79B')   # Color 2 (election)\n",
    "        ],\n",
    "        'Croatia': [\n",
    "            ('2004-01-01', '2011-12-23', '#8DB4E2'),  # Color 1\n",
    "            ('2011-12-23', '2016-01-22', '#C4D79B'),  # Color 2 (election)\n",
    "            ('2016-01-22', '2022-12-31', '#8DB4E2')   # Color 1 (election)\n",
    "        ],\n",
    "        'Great Britain': [\n",
    "            ('2015-01-01', '2016-07-13', '#8DB4E2'),  # Color 1\n",
    "            ('2016-07-13', '2019-07-24', '#C4D79B'),  # Color 2 (election)\n",
    "            ('2019-07-24', '2022-12-31', '#8DB4E2')   # Color 1 (election)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(20, 14), sharex=True)\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    for idx, country in enumerate(countries):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Add background shading for political periods\n",
    "        if add_events and country in periods:\n",
    "            for start, end, color in periods[country]:\n",
    "                start_date = pd.to_datetime(start)\n",
    "                end_date = pd.to_datetime(end)\n",
    "                ax.axvspan(start_date, end_date, alpha=0.15, color=color, zorder=0)\n",
    "        \n",
    "        # Plot data\n",
    "        country_data = temporal_data[temporal_data['Country'] == country].copy()\n",
    "        country_data['YearMonth'] = country_data['Date'].dt.to_period('M')\n",
    "        \n",
    "        monthly = country_data.groupby('YearMonth')[[f'{d}_z' for d in dimensions]].mean()\n",
    "        monthly.columns = [c.replace('_z', '') for c in monthly.columns]\n",
    "        monthly.index = monthly.index.to_timestamp()\n",
    "        monthly_smooth = monthly.rolling(window=3, center=True).mean()\n",
    "        \n",
    "        for dim in monthly_smooth.columns:\n",
    "            ax.plot(monthly_smooth.index, monthly_smooth[dim], linewidth=2.5, label=dim, alpha=0.9, zorder=2)\n",
    "        \n",
    "        # Add event annotations\n",
    "        if add_events and country in events:\n",
    "            for event_date, event_label in events[country]:\n",
    "                event_dt = pd.to_datetime(event_date)\n",
    "                if min_date <= event_dt <= max_date:\n",
    "                    # Draw vertical line\n",
    "                    ax.axvline(x=event_dt, color='red', linestyle='--', \n",
    "                              linewidth=1.5, alpha=0.6, zorder=1)\n",
    "                    \n",
    "                    # Add text annotation at top of plot\n",
    "                    ylim = ax.get_ylim()\n",
    "                    y_pos = ylim[1] * 0.95\n",
    "                    ax.text(event_dt, y_pos, event_label, \n",
    "                           rotation=90, verticalalignment='top', horizontalalignment='right',\n",
    "                           fontsize=8, color='red', fontweight='bold', alpha=0.8)\n",
    "        \n",
    "        ax.axhline(y=0, color='gray', linestyle='-', alpha=0.5, linewidth=1.5, zorder=1)\n",
    "        ax.set_title(country, fontweight='bold', loc='left', fontsize=13)\n",
    "        ax.set_ylabel('Z-Score (3-month avg)', fontweight='bold')\n",
    "        ax.set_xlabel('Year', fontweight='bold', fontsize=12)\n",
    "        ax.grid(True, alpha=0.2, linestyle=':', zorder=0)\n",
    "        ax.set_xlim(min_date, max_date)\n",
    "        \n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=0)\n",
    "        \n",
    "        # Legend - only dimension lines, no events\n",
    "        if idx == 0:\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            # Filter to only include dimension lines (not event markers)\n",
    "            dim_handles = [h for h, l in zip(handles, labels) if l in dimensions]\n",
    "            dim_labels = [l for l in labels if l in dimensions]\n",
    "            ax.legend(dim_handles, dim_labels, \n",
    "                     loc='upper left', ncol=len(dimensions), fontsize=9, framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.99])\n",
    "    plt.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Summary Variables\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['Analytic', 'Authentic', 'Clout', 'Tone'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'], \n",
    "                    'Temporal Evolution: Summary Variables', 'liwc_temporal_summary.png')\n",
    "\n",
    "# Political Language\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['politic', 'power', 'moral', 'money'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'],\n",
    "                    'Temporal Evolution: Political Language', 'liwc_temporal_political.png')\n",
    "\n",
    "# Pronouns\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['i', 'we', 'you', 'they'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'],\n",
    "                    'Temporal Evolution: Pronoun Usage', 'liwc_temporal_pronouns.png')\n",
    "\n",
    "# Cognitive Processes\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['cogproc', 'insight', 'cause', 'certitude'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'],\n",
    "                    'Temporal Evolution: Cognitive Processes', 'liwc_temporal_cognitive.png')\n",
    "\n",
    "# Temporal Focus\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['focuspast', 'focuspresent', 'focusfuture'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'],\n",
    "                    'Temporal Evolution: Time Orientation', 'liwc_temporal_time.png')\n",
    "\n",
    "# Affect and Tone\n",
    "create_temporal_plot(LIWC_ALL, LIWC_benchmarks, ['Affect', 'tone_pos', 'tone_neg'],\n",
    "                    ['Austria', 'Croatia', 'Great Britain'],\n",
    "                    'Temporal Evolution: Emotional Language', 'liwc_temporal_affect.png')\n",
    "\n",
    "print(\"✅ All temporal plots created with events and political periods\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
