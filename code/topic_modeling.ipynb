{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81f5eef",
   "metadata": {},
   "source": [
    "# Topic Modeling with BERTopic on Parliamentary Speeches\n",
    "\n",
    "This notebook implements a sophisticated topic modeling pipeline that:\n",
    "1. **Embeds individual speeches** for semantic segmentation\n",
    "2. **Segments speeches** using similarity-based boundary detection  \n",
    "3. **Re-embeds aggregated segments** for better semantic representation\n",
    "4. **Discovers topics** using BERTopic with custom clustering\n",
    "5. **Generates readable topic names** using LLMs\n",
    "6. **Tracks topic evolution** over time\n",
    "\n",
    "## Key Approach - Dual Embedding Strategy:\n",
    "- **First embedding**: Individual speeches using raw text (for segmentation)\n",
    "- **Second embedding**: Concatenated segment texts (for topic modeling)\n",
    "- **Why twice?** Re-embedding captures full discourse coherence vs. averaging individual embeddings\n",
    "- **Raw text used throughout** for better semantic capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "033f8080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed data: (190633, 28)\n",
      "Loaded original complete data: (231752, 27)\n",
      "\n",
      "Filtered out for topic modeling:\n",
      "  Too short: 41119\n",
      "  Used for topic modeling: 190633\n",
      "\n",
      "Processed data columns: ['Sitting_ID', 'Speech_ID', 'Title', 'Date', 'Body', 'Term', 'Session', 'Meeting', 'Sitting', 'Agenda', 'Subcorpus', 'Lang', 'Speaker_role', 'Speaker_MP', 'Speaker_minister', 'Speaker_party', 'Speaker_party_name', 'Party_status', 'Party_orientation', 'Speaker_ID', 'Speaker_name', 'Speaker_gender', 'Speaker_birth', 'Text', 'Word_Count', 'Is_Too_Short', 'Is_Filtered', 'Used_For_Topic_Modeling']\n",
      "Has 'Text' column: True\n",
      "Loaded original complete data: (231752, 27)\n",
      "\n",
      "Filtered out for topic modeling:\n",
      "  Too short: 41119\n",
      "  Used for topic modeling: 190633\n",
      "\n",
      "Processed data columns: ['Sitting_ID', 'Speech_ID', 'Title', 'Date', 'Body', 'Term', 'Session', 'Meeting', 'Sitting', 'Agenda', 'Subcorpus', 'Lang', 'Speaker_role', 'Speaker_MP', 'Speaker_minister', 'Speaker_party', 'Speaker_party_name', 'Party_status', 'Party_orientation', 'Speaker_ID', 'Speaker_name', 'Speaker_gender', 'Speaker_birth', 'Text', 'Word_Count', 'Is_Too_Short', 'Is_Filtered', 'Used_For_Topic_Modeling']\n",
      "Has 'Text' column: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load PROCESSED data for topic modeling\n",
    "processed_data_path = r'data folder\\data\\AT_for_topic_modeling.pkl'\n",
    "AT_processed_df = pd.read_pickle(processed_data_path)\n",
    "print(f\"Loaded processed data: {AT_processed_df.shape}\")\n",
    "\n",
    "# Load ORIGINAL complete data for final mapping\n",
    "original_data_path = r'data folder\\data\\AT_original_complete.pkl'\n",
    "AT_original_df = pd.read_pickle(original_data_path)\n",
    "print(f\"Loaded original complete data: {AT_original_df.shape}\")\n",
    "\n",
    "print(f\"\\nFiltered out for topic modeling:\")\n",
    "print(f\"  Too short: {AT_original_df['Is_Too_Short'].sum()}\")\n",
    "print(f\"  Used for topic modeling: {len(AT_processed_df)}\")\n",
    "\n",
    "# Verify we have the required columns for the pipeline\n",
    "print(f\"\\nProcessed data columns: {list(AT_processed_df.columns)}\")\n",
    "print(f\"Has 'Text' column: {'Text' in AT_processed_df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e76f3",
   "metadata": {},
   "source": [
    "## Embedding and Segmentation Functions\n",
    "\n",
    "These functions handle the dual-embedding approach:\n",
    "1. **Speech-level embeddings** for similarity-based segmentation\n",
    "2. **Segment-level embeddings** for final topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef87b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.signal import find_peaks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_embedding_model(model_name=\"nomic-ai/nomic-embed-text-v1.5\", device=None):\n",
    "    \"\"\"\n",
    "    Load a sentence embedding model with better memory management.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): HuggingFace model name\n",
    "        device (str): Device to use ('cuda', 'cpu', or None for auto)\n",
    "    \n",
    "    Returns:\n",
    "        SentenceTransformer: Loaded model\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    print(f\"Loading embedding model: {model_name} on {device}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # For CPU, optimize memory usage\n",
    "        if device == 'cpu':\n",
    "            torch.set_num_threads(4)\n",
    "            model = SentenceTransformer(\n",
    "                model_name, \n",
    "                device=device, \n",
    "                trust_remote_code=True,\n",
    "                model_kwargs={'torch_dtype': torch.float32}\n",
    "            )\n",
    "        else:\n",
    "            model = SentenceTransformer(model_name, device=device, trust_remote_code=True)\n",
    "        \n",
    "        print(f\"Model loaded in {time.time() - start_time:.2f} seconds\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_name}: {e}\")\n",
    "        raise e\n",
    "\n",
    "def generate_speech_embeddings_for_segmentation(df, text_column='Text', model_name=\"nomic-ai/nomic-embed-text-v1.5\", batch_size=8):\n",
    "    \"\"\"\n",
    "    FIRST EMBEDDING: Generate embeddings for individual speeches for segmentation.\n",
    "    Uses FULL raw text with fallback for extremely long texts.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with speeches\n",
    "        text_column (str): Column containing text to embed (use 'Text' for raw)\n",
    "        model_name (str): Embedding model to use\n",
    "        batch_size (int): Batch size for embedding generation\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'Speech_Embeddings' column\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"FIRST EMBEDDING: Individual speeches for segmentation\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Generating embeddings for {len(df)} speeches using {model_name}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_embedding_model(model_name)\n",
    "    \n",
    "    # Use FULL texts\n",
    "    texts = df[text_column].astype(str).tolist()\n",
    "    \n",
    "    # Show text length statistics and identify extremely long texts\n",
    "    text_lengths = [len(text) for text in texts]\n",
    "    print(f\"Text length statistics (characters):\")\n",
    "    print(f\"  Min: {min(text_lengths)}, Max: {max(text_lengths)}, Mean: {np.mean(text_lengths):.0f}\")\n",
    "    \n",
    "    # Calculate 99.9th percentile threshold to filter out top 0.1% longest speeches\n",
    "    length_threshold = np.percentile(text_lengths, 99.9)\n",
    "    extremely_long_mask = np.array(text_lengths) > length_threshold\n",
    "    n_extremely_long = extremely_long_mask.sum()\n",
    "    \n",
    "    print(f\"  99.9th percentile length: {length_threshold:.0f} characters\")\n",
    "    print(f\"  Extremely long speeches (top 0.1%): {n_extremely_long}\")\n",
    "    print(f\"  These will be assigned zero embeddings for memory safety\")\n",
    "    \n",
    "    def embed_with_fallback(text, speech_index):\n",
    "        \"\"\"Embed text with fallback strategies for very long texts.\"\"\"\n",
    "        text_len = len(text)\n",
    "        \n",
    "        # Skip extremely long texts (top 0.1%) - assign zero embedding\n",
    "        if text_len > length_threshold:\n",
    "            return np.zeros(model.get_sentence_embedding_dimension())\n",
    "        \n",
    "        try:\n",
    "            # Try full text first\n",
    "            embedding = model.encode(\n",
    "                [text], \n",
    "                batch_size=8,\n",
    "                convert_to_tensor=False,\n",
    "                normalize_embeddings=True,\n",
    "                show_progress_bar=False\n",
    "            )[0]\n",
    "            return embedding\n",
    "            \n",
    "        except Exception:\n",
    "            # Fallback: chunking for very long texts\n",
    "            if len(text) > 10000:\n",
    "                try:\n",
    "                    chunks = []\n",
    "                    chunk_size = 8000\n",
    "                    for i in range(0, len(text), chunk_size):\n",
    "                        chunk = text[i:i + chunk_size]\n",
    "                        if len(chunk.strip()) > 100:\n",
    "                            chunks.append(chunk)\n",
    "                        if len(chunks) >= 3:\n",
    "                            break\n",
    "                    \n",
    "                    if chunks:\n",
    "                        chunk_embeddings = model.encode(\n",
    "                            chunks,\n",
    "                            batch_size=8,\n",
    "                            convert_to_tensor=False,\n",
    "                            normalize_embeddings=True,\n",
    "                            show_progress_bar=False\n",
    "                        )\n",
    "                        return np.mean(chunk_embeddings, axis=0)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            # Final fallback: truncate\n",
    "            try:\n",
    "                truncated_text = text[:5000]\n",
    "                embedding = model.encode(\n",
    "                    [truncated_text],\n",
    "                    batch_size=8,\n",
    "                    convert_to_tensor=False,\n",
    "                    normalize_embeddings=True,\n",
    "                    show_progress_bar=False\n",
    "                )[0]\n",
    "                return embedding\n",
    "            except Exception:\n",
    "                return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    # Generate embeddings with progress bar\n",
    "    print(\"Generating speech-level embeddings...\")\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    \n",
    "    # Create progress bar\n",
    "    progress_bar = tqdm(enumerate(texts), total=len(texts), desc=\"Embedding speeches\", \n",
    "                       unit=\"speech\", ncols=100, \n",
    "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "    \n",
    "    for i, text in progress_bar:\n",
    "        # Memory cleanup every 100 speeches\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        embedding = embed_with_fallback(text, i)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "        # Update progress bar with additional info\n",
    "        if i % 10 == 0:  # Update less frequently to avoid slowing down\n",
    "            progress_bar.set_postfix({\n",
    "                'Rate': f'{i/(time.time()-start_time):.1f} sp/s',\n",
    "                'Long': n_extremely_long\n",
    "            })\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    print(f\"✓ Speech embeddings completed in {time.time() - start_time:.2f} seconds\")\n",
    "    print(f\"✓ Embedding shape: {np.array(embeddings).shape}\")\n",
    "    print(f\"✓ Filtered out {n_extremely_long} extremely long speeches (assigned zero embeddings)\")\n",
    "    \n",
    "    # Final memory cleanup\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Add to dataframe\n",
    "    df_with_embeddings = df.copy()\n",
    "    df_with_embeddings['Speech_Embeddings'] = embeddings\n",
    "    df_with_embeddings['Is_Extremely_Long'] = extremely_long_mask\n",
    "    \n",
    "    return df_with_embeddings\n",
    "\n",
    "def calculate_windowed_similarity(embeddings_list, window_size=3):\n",
    "    \"\"\"\n",
    "    Calculate cosine similarity between windowed embeddings.\n",
    "    \n",
    "    Args:\n",
    "        embeddings_list (list): List of embedding vectors\n",
    "        window_size (int): Size of window for averaging\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Array of similarity scores\n",
    "    \"\"\"\n",
    "    if len(embeddings_list) < 2:\n",
    "        return np.array([])\n",
    "    if window_size < 1:\n",
    "        raise ValueError(\"Window size must be at least 1.\")\n",
    "\n",
    "    num_utterances = len(embeddings_list)\n",
    "    similarities = []\n",
    "\n",
    "    for g in range(num_utterances - 1):\n",
    "        # Window before gap\n",
    "        start_before = max(0, g - window_size + 1)\n",
    "        end_before = g + 1\n",
    "        window_before = embeddings_list[start_before:end_before]\n",
    "\n",
    "        # Window after gap\n",
    "        start_after = g + 1\n",
    "        end_after = min(num_utterances, g + 1 + window_size)\n",
    "        window_after = embeddings_list[start_after:end_after]\n",
    "\n",
    "        if not window_before or not window_after:\n",
    "            similarities.append(0)\n",
    "            continue\n",
    "\n",
    "        # Calculate mean embeddings and similarity\n",
    "        mean_before = np.mean([np.asarray(e) for e in window_before], axis=0)\n",
    "        mean_after = np.mean([np.asarray(e) for e in window_after], axis=0)\n",
    "        \n",
    "        sim = cosine_similarity(mean_before.reshape(1, -1), mean_after.reshape(1, -1))[0][0]\n",
    "        similarities.append(sim)\n",
    "        \n",
    "    return np.array(similarities)\n",
    "\n",
    "def find_topic_boundaries(similarities, height_threshold=0.25, prominence_threshold=0.15, distance_threshold=5):\n",
    "    \"\"\"\n",
    "    Find topic boundaries using peak detection on inverted similarity scores.\n",
    "    \n",
    "    Args:\n",
    "        similarities (np.array): Array of similarity scores\n",
    "        height_threshold (float): Minimum height for peaks in inverted similarities\n",
    "        prominence_threshold (float): Minimum prominence for peaks\n",
    "        distance_threshold (int): Minimum distance between peaks\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Indices of detected boundaries\n",
    "    \"\"\"\n",
    "    if len(similarities) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Invert similarities to find valleys (topic boundaries)\n",
    "    inverted_similarities = np.maximum(0, 1 - similarities)\n",
    "    \n",
    "    # Find peaks in inverted similarities\n",
    "    peaks, _ = find_peaks(\n",
    "        inverted_similarities,\n",
    "        height=height_threshold,\n",
    "        prominence=prominence_threshold,\n",
    "        distance=distance_threshold\n",
    "    )\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "def segment_speeches_by_similarity(df, window_size=3, height_threshold=0.25, \n",
    "                                   prominence_threshold=0.15, distance_threshold=5):\n",
    "    \"\"\"\n",
    "    Segment speeches within each sitting based on semantic similarity using speech embeddings.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with speeches and speech embeddings\n",
    "        window_size (int): Window size for similarity calculation\n",
    "        height_threshold (float): Height threshold for boundary detection\n",
    "        prominence_threshold (float): Prominence threshold for boundary detection\n",
    "        distance_threshold (int): Distance threshold for boundary detection\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'Segment_ID' column\n",
    "    \"\"\"\n",
    "    print(f\"Segmenting speeches using similarity-based approach\")\n",
    "    print(f\"Parameters: window_size={window_size}, height_threshold={height_threshold}\")\n",
    "    print(f\"           prominence_threshold={prominence_threshold}, distance_threshold={distance_threshold}\")\n",
    "    \n",
    "    df_segmented = df.copy()\n",
    "    segment_ids = []\n",
    "    total_boundaries = 0\n",
    "    \n",
    "    # Process each sitting separately\n",
    "    for sitting_id, group in df_segmented.groupby('Sitting_ID'):\n",
    "        if len(group) < 2:\n",
    "            # Not enough speeches for segmentation\n",
    "            segment_ids.extend([f\"{sitting_id}_seg_0\"] * len(group))\n",
    "            continue\n",
    "        \n",
    "        # Use the speech-level embeddings for segmentation\n",
    "        embeddings_list = group['Speech_Embeddings'].tolist()\n",
    "        similarities = calculate_windowed_similarity(embeddings_list, window_size)\n",
    "        \n",
    "        if len(similarities) == 0:\n",
    "            segment_ids.extend([f\"{sitting_id}_seg_0\"] * len(group))\n",
    "            continue\n",
    "        \n",
    "        # Find boundaries\n",
    "        boundaries = find_topic_boundaries(\n",
    "            similarities, height_threshold, prominence_threshold, distance_threshold\n",
    "        )\n",
    "        total_boundaries += len(boundaries)\n",
    "        \n",
    "        # Assign segment IDs\n",
    "        current_segment = 0\n",
    "        sitting_segment_ids = []\n",
    "        \n",
    "        for i in range(len(group)):\n",
    "            # Check if this speech starts a new segment\n",
    "            if i > 0 and (i - 1) in boundaries:\n",
    "                current_segment += 1\n",
    "            sitting_segment_ids.append(f\"{sitting_id}_seg_{current_segment}\")\n",
    "        \n",
    "        segment_ids.extend(sitting_segment_ids)\n",
    "    \n",
    "    df_segmented['Segment_ID'] = segment_ids\n",
    "    \n",
    "    # Print statistics\n",
    "    total_segments = df_segmented['Segment_ID'].nunique()\n",
    "    avg_segments_per_sitting = df_segmented.groupby('Sitting_ID')['Segment_ID'].nunique().mean()\n",
    "    \n",
    "    print(f\"Segmentation complete!\")\n",
    "    print(f\"Total boundaries detected: {total_boundaries}\")\n",
    "    print(f\"Total segments created: {total_segments}\")\n",
    "    print(f\"Average segments per sitting: {avg_segments_per_sitting:.2f}\")\n",
    "    \n",
    "    return df_segmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c553c",
   "metadata": {},
   "source": [
    "## Segment Aggregation and Re-embedding Functions\n",
    "\n",
    "After creating segments, we aggregate the raw text and re-embed for better topic modeling representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da375b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_segments(df, text_column='Text'):\n",
    "    \"\"\"\n",
    "    Aggregate speeches into segments using FULL raw text for maximum semantic coherence.\n",
    "    \"\"\"\n",
    "    print(f\"Aggregating {len(df)} speeches into segments using FULL raw text...\")\n",
    "    \n",
    "    # Check for extremely long speeches in segments\n",
    "    if 'Is_Extremely_Long' in df.columns:\n",
    "        n_extremely_long = df['Is_Extremely_Long'].sum()\n",
    "        if n_extremely_long > 0:\n",
    "            print(f\"Note: {n_extremely_long} speeches were marked as extremely long (zero embeddings)\")\n",
    "    \n",
    "    # Aggregate by segment\n",
    "    segment_agg = df.groupby('Segment_ID').agg({\n",
    "        text_column: ' '.join,  # Concatenate ALL raw texts in segment\n",
    "        'Sitting_ID': 'first',\n",
    "        'Date': 'first',\n",
    "        'Speaker_party': lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0],\n",
    "        'Speaker_name': lambda x: ' | '.join(x.unique()[:3]),\n",
    "        'Word_Count': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename aggregated text column\n",
    "    segment_agg.rename(columns={text_column: 'Aggregated_Text'}, inplace=True)\n",
    "    \n",
    "    # Show segment statistics\n",
    "    segment_lengths = [len(text) for text in segment_agg['Aggregated_Text']]\n",
    "    print(f\"Created {len(segment_agg)} segments\")\n",
    "    print(f\"Segment length - Min: {min(segment_lengths)}, Max: {max(segment_lengths)}, Mean: {np.mean(segment_lengths):.0f}\")\n",
    "    \n",
    "    # Check if any segments are now extremely long after aggregation\n",
    "    segment_threshold = np.percentile(segment_lengths, 99.5)  # Slightly less strict for segments\n",
    "    very_long_segments = sum(1 for length in segment_lengths if length > segment_threshold)\n",
    "    if very_long_segments > 0:\n",
    "        print(f\"Warning: {very_long_segments} segments are very long (>{segment_threshold:.0f} chars)\")\n",
    "    \n",
    "    return segment_agg\n",
    "\n",
    "def generate_segment_embeddings_for_topic_modeling(segment_df, model_name=\"BAAI/bge-m3\"):\n",
    "    \"\"\"\n",
    "    SECOND EMBEDDING: Generate embeddings for aggregated segments for topic modeling.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SECOND EMBEDDING: Aggregated segments for topic modeling\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Generating embeddings for {len(segment_df)} segments using {model_name}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_embedding_model(model_name)\n",
    "    \n",
    "    # Calculate segment length threshold (top 0.5% of segments)\n",
    "    segment_lengths = [len(text) for text in segment_df['Aggregated_Text']]\n",
    "    segment_threshold = np.percentile(segment_lengths, 99.5)\n",
    "    print(f\"Segment length threshold (99.5th percentile): {segment_threshold:.0f} characters\")\n",
    "    \n",
    "    def embed_single_segment(text, index):\n",
    "        \"\"\"Embed a single segment using the FULL text with length checking.\"\"\"\n",
    "        text_len = len(text)\n",
    "        \n",
    "        # Skip extremely long segments\n",
    "        if text_len > segment_threshold:\n",
    "            return np.zeros(model.get_sentence_embedding_dimension())\n",
    "        \n",
    "        try:\n",
    "            return model.encode(\n",
    "                text, \n",
    "                convert_to_tensor=False, \n",
    "                normalize_embeddings=True,\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding segment {index+1} (length: {len(text)} chars): {e}\")\n",
    "            return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    # Generate embeddings with progress bar\n",
    "    print(\"Generating segment embeddings...\")\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    \n",
    "    # Create progress bar for segments\n",
    "    progress_bar = tqdm(enumerate(segment_df['Aggregated_Text']), \n",
    "                       total=len(segment_df), \n",
    "                       desc=\"Embedding segments\", \n",
    "                       unit=\"segment\", \n",
    "                       ncols=100,\n",
    "                       bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "    \n",
    "    for i, text in progress_bar:\n",
    "        if i % 10 == 0 and i > 0:\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        embedding = embed_single_segment(text, i)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "        # Update progress bar with rate info\n",
    "        if i % 5 == 0:\n",
    "            progress_bar.set_postfix({\n",
    "                'Rate': f'{i/(time.time()-start_time):.1f} seg/s'\n",
    "            })\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    print(f\"✓ Segment embeddings completed in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Final memory cleanup\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Add to dataframe\n",
    "    segment_df_with_embeddings = segment_df.copy()\n",
    "    segment_df_with_embeddings['Segment_Embeddings'] = embeddings\n",
    "    \n",
    "    return segment_df_with_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cebbdf",
   "metadata": {},
   "source": [
    "## Topic Modeling Functions\n",
    "\n",
    "These functions handle BERTopic training using the re-embedded segment representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab2c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from umap import UMAP\n",
    "\n",
    "def create_topic_model(clustering_method='kmeans', n_clusters=12, min_cluster_size=30, \n",
    "                       custom_stopwords=None, top_n_words=8, n_segments=None):\n",
    "    \"\"\"\n",
    "    Create a BERTopic model with specified clustering method and validation.\n",
    "    \n",
    "    Args:\n",
    "        clustering_method (str): 'kmeans' or 'hdbscan'\n",
    "        n_clusters (int): Number of clusters for KMeans\n",
    "        min_cluster_size (int): Minimum cluster size for HDBSCAN\n",
    "        custom_stopwords (list): Additional stopwords\n",
    "        top_n_words (int): Number of keywords per topic\n",
    "        n_segments (int): Number of segments to validate against\n",
    "    \n",
    "    Returns:\n",
    "        BERTopic: Configured BERTopic model\n",
    "    \"\"\"\n",
    "    # Default custom stopwords for parliamentary speeches\n",
    "    if custom_stopwords is None:\n",
    "        custom_stopwords = [\n",
    "            'mr', 'mrs', 'ms', 'madam', 'honourable', 'member', 'members', 'vp', 'sp', 'fp',\n",
    "            'minister', 'speaker', 'deputy', 'president', 'chairman', 'chair', 'secretary',\n",
    "            'motion', 'amendment', 'debate', 'question', 'order', 'point', 'procedure',\n",
    "            'applause', 'thank', 'thanks', 'congratulations', 'welcome', 'session', 'meeting'\n",
    "        ]\n",
    "    \n",
    "    # Combine with default English stopwords\n",
    "    all_stopwords = list(text.ENGLISH_STOP_WORDS.union(custom_stopwords))\n",
    "    \n",
    "    # Validate data size and adjust parameters\n",
    "    if n_segments is not None:\n",
    "        if n_segments < 15:\n",
    "            print(f\"Warning: Only {n_segments} segments available. Adjusting model parameters for small dataset.\")\n",
    "            if clustering_method.lower() == 'kmeans':\n",
    "                n_clusters = min(n_clusters, max(2, n_segments // 2))\n",
    "                print(f\"Adjusted n_clusters to {n_clusters}\")\n",
    "            else:\n",
    "                min_cluster_size = min(min_cluster_size, max(2, n_segments // 3))\n",
    "                print(f\"Adjusted min_cluster_size to {min_cluster_size}\")\n",
    "    \n",
    "    # Choose clustering model\n",
    "    if clustering_method.lower() == 'kmeans':\n",
    "        clustering_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        print(f\"Using KMeans clustering with {n_clusters} clusters\")\n",
    "    elif clustering_method.lower() == 'hdbscan':\n",
    "        clustering_model = hdbscan.HDBSCAN(\n",
    "            min_cluster_size=min_cluster_size,\n",
    "            min_samples=min_cluster_size,\n",
    "            metric='euclidean',\n",
    "            cluster_selection_method='eom',\n",
    "            prediction_data=True\n",
    "        )\n",
    "        print(f\"Using HDBSCAN clustering with min_cluster_size={min_cluster_size}\")\n",
    "    else:\n",
    "        raise ValueError(\"clustering_method must be 'kmeans' or 'hdbscan'\")\n",
    "    \n",
    "    # Create vectorizer\n",
    "    vectorizer = CountVectorizer(stop_words=all_stopwords)\n",
    "    \n",
    "    # Configure UMAP for small datasets\n",
    "    if n_segments is not None and n_segments < 15:\n",
    "        umap_model = UMAP(\n",
    "            n_neighbors=min(5, n_segments - 1),\n",
    "            n_components=min(5, n_segments - 1),\n",
    "            metric='cosine',\n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Using UMAP with adjusted parameters for small dataset\")\n",
    "    else:\n",
    "        umap_model = UMAP(\n",
    "            n_neighbors=15,\n",
    "            n_components=5,\n",
    "            metric='cosine',\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    # Create BERTopic model\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=None,  # We provide pre-computed embeddings\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=clustering_model,\n",
    "        vectorizer_model=vectorizer,\n",
    "        top_n_words=top_n_words,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return topic_model\n",
    "\n",
    "def train_topic_model(segment_df, clustering_method='kmeans', n_clusters=12):\n",
    "    \"\"\"\n",
    "    Train BERTopic model on aggregated segments using segment embeddings.\n",
    "    \n",
    "    Args:\n",
    "        segment_df (pd.DataFrame): DataFrame with segments and segment embeddings\n",
    "        clustering_method (str): Clustering method to use\n",
    "        n_clusters (int): Number of clusters for KMeans\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (topic_model, segment_df_with_topics, topic_info)\n",
    "    \"\"\"\n",
    "    print(f\"Training BERTopic model on {len(segment_df)} segments\")\n",
    "    \n",
    "    # Validate minimum data requirements\n",
    "    if len(segment_df) < 5:\n",
    "        print(f\"ERROR: Only {len(segment_df)} segments available. Need at least 5 segments for topic modeling.\")\n",
    "        print(\"Suggestions:\")\n",
    "        print(\"1. Use a larger test sample (try 200-500 speeches instead of 50)\")\n",
    "        print(\"2. Adjust segmentation parameters to create fewer, larger segments\")\n",
    "        print(\"3. Skip topic modeling for very small datasets\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Create model with validation\n",
    "    topic_model = create_topic_model(\n",
    "        clustering_method=clustering_method, \n",
    "        n_clusters=n_clusters,\n",
    "        n_segments=len(segment_df)\n",
    "    )\n",
    "    \n",
    "    # Prepare data - use the segment embeddings (not speech embeddings)\n",
    "    texts = segment_df['Aggregated_Text'].tolist()\n",
    "    embeddings = np.array(segment_df['Segment_Embeddings'].tolist())\n",
    "    \n",
    "    print(f\"Using segment embeddings with shape: {embeddings.shape}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training BERTopic...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        topics, probabilities = topic_model.fit_transform(texts, embeddings=embeddings)\n",
    "        print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"BERTopic training failed: {e}\")\n",
    "        print(\"This often happens with very small datasets. Try using more data.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Add topics to dataframe\n",
    "    segment_df_with_topics = segment_df.copy()\n",
    "    segment_df_with_topics['Topic'] = topics\n",
    "    \n",
    "    # Get topic info\n",
    "    topic_info = topic_model.get_topic_info()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Discovered {len(topic_info)} topics\")\n",
    "    if clustering_method.lower() == 'hdbscan':\n",
    "        outliers = (topics == -1).sum()\n",
    "        print(f\"Outliers: {outliers} ({outliers/len(topics)*100:.1f}%)\")\n",
    "    \n",
    "    return topic_model, segment_df_with_topics, topic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc6cef",
   "metadata": {},
   "source": [
    "## Main Processing Pipeline\n",
    "\n",
    "Updated pipeline implementing the dual-embedding approach correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "963a868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting topic modeling pipeline on full dataset...\n",
      "=== DUAL EMBEDDING PIPELINE USING RAW TEXT ===\n",
      "Input data shape: (190633, 28)\n",
      "Using RAW text for both embeddings (better semantic quality)\n",
      "\n",
      "=== STEP 1: FIRST EMBEDDING - Individual Speeches (Raw Text) for Segmentation ===\n",
      "============================================================\n",
      "FIRST EMBEDDING: Individual speeches for segmentation\n",
      "============================================================\n",
      "Generating embeddings for 190633 speeches using nomic-ai/nomic-embed-text-v1.5\n",
      "Loading embedding model: nomic-ai/nomic-embed-text-v1.5 on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 6.23 seconds\n",
      "Text length statistics (characters):\n",
      "  Min: 40, Max: 238216, Mean: 2057\n",
      "  99.9th percentile length: 21750 characters\n",
      "  Extremely long speeches (top 0.1%): 191\n",
      "  These will be assigned zero embeddings for memory safety\n",
      "Generating speech-level embeddings...\n",
      "Starting embedding generation...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 144\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting topic modeling pipeline on full dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# Run on full dataset\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     results = \u001b[43mrun_dual_embedding_topic_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAT_processed_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError in pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mrun_dual_embedding_topic_pipeline\u001b[39m\u001b[34m(df, save_intermediate, data_folder)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Step 1: Generate speech embeddings for segmentation (FIRST EMBEDDING - RAW TEXT)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== STEP 1: FIRST EMBEDDING - Individual Speeches (Raw Text) for Segmentation ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m df_with_speech_embeddings = \u001b[43mgenerate_speech_embeddings_for_segmentation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mText\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use RAW text from 'Text' column\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnomic-ai/nomic-embed-text-v1.5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Back to original model\u001b[39;49;00m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Very small batch size for memory safety\u001b[39;49;00m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mdf_with_speech_embeddings\u001b[39m\u001b[33m'\u001b[39m] = df_with_speech_embeddings\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_intermediate:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mgenerate_speech_embeddings_for_segmentation\u001b[39m\u001b[34m(df, text_column, model_name, batch_size)\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m    165\u001b[39m             torch.cuda.empty_cache()\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     embedding = \u001b[43membed_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     embeddings.append(embedding)\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Speech embeddings completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mgenerate_speech_embeddings_for_segmentation.<locals>.embed_with_fallback\u001b[39m\u001b[34m(text, speech_index)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros(model.get_sentence_embedding_dimension())\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# Try full text first\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     embedding = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Fallback: chunking for very long texts\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:685\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    682\u001b[39m features.update(extra_features)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    687\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:752\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    750\u001b[39m     module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m    751\u001b[39m     module_kwargs = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[32m--> \u001b[39m\u001b[32m752\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:442\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m trans_features = {\n\u001b[32m    437\u001b[39m     key: value\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    440\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m output_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m output_tokens = output_states[\u001b[32m0\u001b[39m]\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# If the AutoModel is wrapped with a PeftModelForFeatureExtraction, then it may have added virtual tokens\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# We need to extend the attention mask to include these virtual tokens, or the pooling will fail\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\7710840340a098cfb869c4f65e87cf2b1b70caca\\modeling_hf_nomic_bert.py:1915\u001b[39m, in \u001b[36mNomicBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, token_type_ids, return_dict, matryoshka_dim, inputs_embeds)\u001b[39m\n\u001b[32m   1912\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.emb_drop(hidden_states)\n\u001b[32m   1914\u001b[39m attention_mask = \u001b[38;5;28mself\u001b[39m.get_extended_attention_mask(attention_mask, hidden_states.shape[:-\u001b[32m1\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m sequence_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1917\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m matryoshka_dim:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\7710840340a098cfb869c4f65e87cf2b1b70caca\\modeling_hf_nomic_bert.py:1794\u001b[39m, in \u001b[36mNomicBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, is_padded_inputs, rope)\u001b[39m\n\u001b[32m   1773\u001b[39m         hidden_states, hidden_states2, residual = torch.utils.checkpoint.checkpoint(\n\u001b[32m   1774\u001b[39m             create_custom_forward(layer),\n\u001b[32m   1775\u001b[39m             hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1790\u001b[39m             use_reentrant=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1791\u001b[39m         )\n\u001b[32m   1793\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m         hidden_states, hidden_states2, residual = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhidden_states2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1798\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1800\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrope\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1805\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\7710840340a098cfb869c4f65e87cf2b1b70caca\\modeling_hf_nomic_bert.py:1713\u001b[39m, in \u001b[36mNomicBertBlock.forward\u001b[39m\u001b[34m(self, hidden_states, hidden_states2, residual, attention_mask, position_ids, past_key_value, is_padded_inputs, output_attentions, use_cache, cu_seqlens, max_seq_len, rope)\u001b[39m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1712\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m residual \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1713\u001b[39m     attn_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1714\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1715\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1716\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_padded_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcu_seqlens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrope\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1721\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.norm1((\u001b[38;5;28mself\u001b[39m.dropout1(attn_outputs) + hidden_states).to(dtype=\u001b[38;5;28mself\u001b[39m.norm1.weight.dtype))\n\u001b[32m   1722\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.moe:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\nomic-ai\\nomic-bert-2048\\7710840340a098cfb869c4f65e87cf2b1b70caca\\modeling_hf_nomic_bert.py:1595\u001b[39m, in \u001b[36mNomicBertAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, is_padded_inputs, cu_seqlens, max_seq_len, rope)\u001b[39m\n\u001b[32m   1591\u001b[39m     attn_output = torch.matmul(attentions_probs, value)\n\u001b[32m   1593\u001b[39m attn_output = rearrange(attn_output.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m... h d -> ... (h d)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m attn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavle\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_dual_embedding_topic_pipeline(df, save_intermediate=True, data_folder='data folder/data/'):\n",
    "    \"\"\"\n",
    "    Run the complete dual-embedding topic modeling pipeline.\n",
    "    \n",
    "    DUAL EMBEDDING STRATEGY:\n",
    "    1. First embedding: Individual speeches using RAW TEXT (for segmentation)\n",
    "    2. Second embedding: Aggregated segments using RAW TEXT (for topic modeling)\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe with speeches (should contain raw text)\n",
    "        save_intermediate (bool): Whether to save intermediate results\n",
    "        data_folder (str): Folder to save results\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Verify we have the required columns - simplified requirements\n",
    "    required_cols = ['Text', 'Sitting_ID', 'Speaker_ID']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Missing required columns: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    print(\"=== DUAL EMBEDDING PIPELINE USING RAW TEXT ===\")\n",
    "    print(f\"Input data shape: {df.shape}\")\n",
    "    print(f\"Using RAW text for both embeddings (better semantic quality)\")\n",
    "    \n",
    "    # Step 1: Generate speech embeddings for segmentation (FIRST EMBEDDING - RAW TEXT)\n",
    "    print(\"\\n=== STEP 1: FIRST EMBEDDING - Individual Speeches (Raw Text) for Segmentation ===\")\n",
    "    df_with_speech_embeddings = generate_speech_embeddings_for_segmentation(\n",
    "        df, \n",
    "        text_column='Text',  # Use RAW text from 'Text' column\n",
    "        model_name=\"nomic-ai/nomic-embed-text-v1.5\",  # Back to original model\n",
    "        batch_size=8  # Very small batch size for memory safety\n",
    "    )\n",
    "    results['df_with_speech_embeddings'] = df_with_speech_embeddings\n",
    "    \n",
    "    if save_intermediate:\n",
    "        df_with_speech_embeddings.to_pickle(f'{data_folder}AT_with_speech_embeddings_raw.pkl')\n",
    "        print(f\"Saved speech embeddings (raw text) to {data_folder}AT_with_speech_embeddings_raw.pkl\")\n",
    "    \n",
    "    # Step 2: Segment speeches using speech embeddings\n",
    "    print(\"\\n=== STEP 2: Segmenting Speeches Using Speech Embeddings ===\")\n",
    "    df_segmented = segment_speeches_by_similarity(\n",
    "        df_with_speech_embeddings,\n",
    "        window_size=3,\n",
    "        height_threshold=0.25,\n",
    "        prominence_threshold=0.15,\n",
    "        distance_threshold=5\n",
    "    )\n",
    "    results['df_segmented'] = df_segmented\n",
    "    \n",
    "    # Step 3: Aggregate segments (concatenate RAW text)\n",
    "    print(\"\\n=== STEP 3: Aggregating Segments (Raw Text Concatenation) ===\")\n",
    "    segments_df = aggregate_segments(df_segmented, text_column='Text')  # Use RAW text\n",
    "    results['segments_df'] = segments_df\n",
    "    \n",
    "    # Step 4: Generate segment embeddings for topic modeling (SECOND EMBEDDING - RAW TEXT)\n",
    "    print(\"\\n=== STEP 4: SECOND EMBEDDING - Aggregated Segments (Raw Text) for Topic Modeling ===\")\n",
    "    segments_with_embeddings = generate_segment_embeddings_for_topic_modeling(\n",
    "        segments_df,\n",
    "        model_name=\"BAAI/bge-m3\"  # Keep original model\n",
    "    )\n",
    "    results['segments_with_embeddings'] = segments_with_embeddings\n",
    "    \n",
    "    if save_intermediate:\n",
    "        segments_with_embeddings.to_pickle(f'{data_folder}AT_segments_with_embeddings_raw.pkl')\n",
    "        print(f\"Saved segment embeddings (raw text) to {data_folder}AT_segments_with_embeddings_raw.pkl\")\n",
    "    \n",
    "    # Step 5: Train topic model using segment embeddings\n",
    "    print(\"\\n=== STEP 5: Training Topic Model Using Segment Embeddings ===\")\n",
    "    topic_model, segments_with_topics, topic_info = train_topic_model(\n",
    "        segments_with_embeddings,\n",
    "        clustering_method='kmeans',\n",
    "        n_clusters=12\n",
    "    )\n",
    "    results['topic_model'] = topic_model\n",
    "    results['segments_with_topics'] = segments_with_topics\n",
    "    results['topic_info'] = topic_info\n",
    "    \n",
    "    # Step 6: Generate topic names using LLM\n",
    "    print(\"\\n=== STEP 6: Generating Topic Names ===\")\n",
    "    try:\n",
    "        topic_info_with_names = generate_topic_names_with_llm(topic_info)\n",
    "    except Exception as e:\n",
    "        print(f\"LLM naming failed: {e}. Using default names.\")\n",
    "        topic_info_with_names = topic_info.copy()\n",
    "        topic_info_with_names['LLM_Name'] = topic_info_with_names.apply(lambda row: f\"Topic {row['Topic']}\", axis=1)\n",
    "    \n",
    "    results['topic_info_with_names'] = topic_info_with_names\n",
    "    \n",
    "    # Step 7: Map topics back to original speeches\n",
    "    print(\"\\n=== STEP 7: Mapping Topics Back to Individual Speeches ===\")\n",
    "    \n",
    "    # Create segment-to-topic mapping\n",
    "    segment_topic_map = segments_with_topics[['Segment_ID', 'Topic']].copy()\n",
    "    \n",
    "    # Map topics back to individual speeches\n",
    "    df_with_topics = df_segmented.merge(segment_topic_map, on='Segment_ID', how='left')\n",
    "    \n",
    "    # Create topic name mapping\n",
    "    topic_name_map = dict(zip(topic_info_with_names['Topic'], topic_info_with_names['LLM_Name']))\n",
    "    \n",
    "    # Add readable topic names\n",
    "    df_with_topics['Topic_Name'] = df_with_topics['Topic'].map(topic_name_map)\n",
    "    \n",
    "    results['df_with_topics'] = df_with_topics\n",
    "    results['topic_name_map'] = topic_name_map\n",
    "    \n",
    "    # Check merge success\n",
    "    missing_topics = df_with_topics['Topic'].isna().sum()\n",
    "    if missing_topics > 0:\n",
    "        print(f\"Warning: {missing_topics} speeches could not be mapped to topics\")\n",
    "    else:\n",
    "        print(\"✓ All speeches successfully mapped to topics!\")\n",
    "    \n",
    "    # Final save\n",
    "    if save_intermediate:\n",
    "        # Clean up speech embeddings before saving final result to save space\n",
    "        df_final_clean = df_with_topics.drop(columns=['Speech_Embeddings'], errors='ignore')\n",
    "        df_final_clean.to_pickle(f'{data_folder}AT_with_topics_final.pkl')\n",
    "        topic_info_with_names.to_csv(f'{data_folder}topic_info_with_names.csv', index=False)\n",
    "        print(f\"Saved final results to {data_folder}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"DUAL EMBEDDING PIPELINE COMPLETE - USING RAW TEXT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"✓ Processed {len(df)} speeches into {len(segments_df)} segments\")\n",
    "    print(f\"✓ Used RAW text for both speech-level and segment-level embeddings\")\n",
    "    print(f\"✓ Discovered {len(topic_info)} topics using segment embeddings\")\n",
    "    print(f\"✓ Successfully mapped {len(df_with_topics) - missing_topics} speeches to topics\")\n",
    "    print(f\"✓ Embedding approach: Raw Speech Text → Segmentation → Raw Segment Text → Topics\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the dual-embedding pipeline directly on full dataset\n",
    "print(\"Starting topic modeling pipeline on full dataset...\")\n",
    "\n",
    "try:\n",
    "    # Run on full dataset\n",
    "    results = run_dual_embedding_topic_pipeline(AT_processed_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64631623",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Extract results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_final = \u001b[43mresults\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdf_with_topics\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m topic_info = results[\u001b[33m'\u001b[39m\u001b[33mtopic_info_with_names\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m segments_df = results[\u001b[33m'\u001b[39m\u001b[33msegments_with_topics\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract results only if the pipeline succeeded\n",
    "if 'results' in locals() and results is not None:\n",
    "    df_final = results['df_with_topics']\n",
    "    topic_info = results['topic_info_with_names']\n",
    "    segments_df = results['segments_with_topics']\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"DUAL EMBEDDING PIPELINE VALIDATION - RAW TEXT APPROACH\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Verify dual embedding approach with raw text\n",
    "    print(\"✓ FIRST EMBEDDING: Individual speeches using RAW text for segmentation\")\n",
    "    print(f\"  - Speech embeddings shape: {len(results['df_with_speech_embeddings'])}\")\n",
    "    print(f\"  - Used RAW text for better semantic boundary detection\")\n",
    "\n",
    "    print(\"\\n✓ SECOND EMBEDDING: Aggregated segments using RAW text for topic modeling\")\n",
    "    print(f\"  - Segment embeddings shape: {len(results['segments_with_embeddings'])}\")\n",
    "    print(f\"  - Used concatenated RAW text for better topic representation\")\n",
    "\n",
    "    # Topic summary\n",
    "    print(f\"\\n✓ TOPICS DISCOVERED:\")\n",
    "    for _, row in topic_info.iterrows():\n",
    "        if row['Topic'] != -1:  # Skip outlier topic if any\n",
    "            print(f\"  Topic {row['Topic']}: {row['LLM_Name']} ({row['Count']} segments)\")\n",
    "\n",
    "    # Verify RAW text was used throughout (more comprehensive check)\n",
    "    sample_segment = segments_df.iloc[0]['Aggregated_Text']\n",
    "    print(f\"\\n✓ RAW TEXT VERIFICATION (sample segment):\")\n",
    "    print(f\"  Contains punctuation: {'.' in sample_segment}\")\n",
    "    print(f\"  Contains capitals: {any(c.isupper() for c in sample_segment)}\")\n",
    "    print(f\"  Contains common words: {'the' in sample_segment.lower()}\")\n",
    "    print(f\"  Contains parliamentary formalities: {'Mr.' in sample_segment or 'Speaker' in sample_segment}\")\n",
    "    print(f\"  Length: {len(sample_segment)} chars\")\n",
    "    print(f\"  Sample: '{sample_segment[:150]}...'\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RAW TEXT DUAL EMBEDDING APPROACH SUCCESSFULLY IMPLEMENTED!\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"Pipeline did not complete successfully. Results not available for validation.\")\n",
    "    print(\"This usually happens when:\")\n",
    "    print(\"1. The test dataset is too small (creates too few segments)\")\n",
    "    print(\"2. Segmentation parameters are too restrictive\")\n",
    "    print(\"3. Memory or model loading issues\")\n",
    "    print(\"\\nTry running with more speeches in the test set or adjust segmentation parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef32875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_topics_back_to_original(original_df, processed_df_with_topics, segment_df_with_topics):\n",
    "    \"\"\"\n",
    "    Map topics back to the original complete dataframe, including filtered speeches.\n",
    "    \n",
    "    Args:\n",
    "        original_df: Complete original dataframe\n",
    "        processed_df_with_topics: Processed dataframe with topic assignments\n",
    "        segment_df_with_topics: Segment-level dataframe with topics\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original dataframe with topic assignments\n",
    "    \"\"\"\n",
    "    print(\"Mapping topics back to original complete dataframe...\")\n",
    "    \n",
    "    # Start with original dataframe\n",
    "    result_df = original_df.copy()\n",
    "    result_df['Topic'] = None\n",
    "    result_df['Topic_Assignment_Method'] = None\n",
    "    \n",
    "    # 1. Direct mapping for speeches that went through topic modeling\n",
    "    print(\"1. Direct mapping for processed speeches...\")\n",
    "    \n",
    "    # Create mapping from processed speeches to topics\n",
    "    if 'Speech_ID' in processed_df_with_topics.columns:\n",
    "        # Use Speech_ID for mapping\n",
    "        speech_topic_map = processed_df_with_topics.set_index('Speech_ID')['Topic_Name'].to_dict()\n",
    "        mask = result_df['Speech_ID'].isin(speech_topic_map.keys())\n",
    "        result_df.loc[mask, 'Topic'] = result_df.loc[mask, 'Speech_ID'].map(speech_topic_map)\n",
    "        result_df.loc[mask, 'Topic_Assignment_Method'] = 'Direct'\n",
    "        direct_assigned = mask.sum()\n",
    "    else:\n",
    "        # Fallback: try index-based mapping (less reliable)\n",
    "        direct_assigned = 0\n",
    "        print(\"Warning: No Speech_ID found for direct mapping\")\n",
    "    \n",
    "    print(f\"   Directly assigned: {direct_assigned}\")\n",
    "    \n",
    "    # 2. Contextual assignment for short speeches\n",
    "    print(\"2. Contextual assignment for short speeches...\")\n",
    "    short_speeches = result_df['Is_Too_Short'] & result_df['Topic'].isna()\n",
    "    contextual_assigned = 0\n",
    "    \n",
    "    for idx in result_df[short_speeches].index:\n",
    "        sitting_id = result_df.loc[idx, 'Sitting_ID']\n",
    "        \n",
    "        # Find other speeches in same sitting with topics\n",
    "        same_sitting = result_df[\n",
    "            (result_df['Sitting_ID'] == sitting_id) & \n",
    "            (result_df['Topic'].notna())\n",
    "        ]\n",
    "        \n",
    "        if len(same_sitting) > 0:\n",
    "            # Get most common topic in this sitting\n",
    "            most_common_topic = same_sitting['Topic'].mode()\n",
    "            if len(most_common_topic) > 0:\n",
    "                result_df.loc[idx, 'Topic'] = most_common_topic.iloc[0]\n",
    "                result_df.loc[idx, 'Topic_Assignment_Method'] = 'Contextual'\n",
    "                contextual_assigned += 1\n",
    "    \n",
    "    print(f\"   Contextually assigned: {contextual_assigned}\")\n",
    "    \n",
    "    # 3. Handle remaining unassigned speeches\n",
    "    print(\"3. Handling remaining unassigned speeches...\")\n",
    "    \n",
    "    # Short speeches without context\n",
    "    short_unassigned = result_df['Is_Too_Short'] & result_df['Topic'].isna()\n",
    "    result_df.loc[short_unassigned, 'Topic'] = 'Procedural'\n",
    "    result_df.loc[short_unassigned, 'Topic_Assignment_Method'] = 'Procedural'\n",
    "    \n",
    "    # Any other unassigned\n",
    "    still_unassigned = result_df['Topic'].isna()\n",
    "    result_df.loc[still_unassigned, 'Topic'] = 'Unclassified'\n",
    "    result_df.loc[still_unassigned, 'Topic_Assignment_Method'] = 'Unclassified'\n",
    "    \n",
    "    print(f\"   Short speeches marked as 'Procedural': {short_unassigned.sum()}\")\n",
    "    print(f\"   Other unassigned marked as 'Unclassified': {still_unassigned.sum()}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nFinal topic assignment summary:\")\n",
    "    assignment_counts = result_df['Topic_Assignment_Method'].value_counts()\n",
    "    for method, count in assignment_counts.items():\n",
    "        print(f\"   {method}: {count}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Run complete pipeline with correct variable names (only if results exist)\n",
    "def run_complete_topic_pipeline(processed_df, original_df, save_results=True):\n",
    "    \"\"\"\n",
    "    Complete pipeline that processes topics and maps back to original data.\n",
    "    \"\"\"\n",
    "    # Run existing topic modeling pipeline\n",
    "    results = run_dual_embedding_topic_pipeline(processed_df, save_intermediate=True)\n",
    "    \n",
    "    if results is None:\n",
    "        print(\"Topic modeling pipeline failed. Cannot proceed with mapping.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Map back to original complete dataframe\n",
    "    final_df = map_topics_back_to_original(\n",
    "        original_df, \n",
    "        results['df_with_topics'], \n",
    "        results['segments_with_topics']\n",
    "    )\n",
    "    \n",
    "    if save_results:\n",
    "        final_df.to_pickle('data folder/data/AT_complete_with_topics.pkl')\n",
    "        print(\"Saved complete dataframe with topics to 'AT_complete_with_topics.pkl'\")\n",
    "    \n",
    "    return final_df, results\n",
    "\n",
    "# Only run complete pipeline if the test succeeded\n",
    "if 'results' in locals() and results is not None:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RUNNING COMPLETE PIPELINE ON FULL DATASET\")\n",
    "    print(\"=\" * 70)\n",
    "    AT_final, topic_results = run_complete_topic_pipeline(AT_processed_df, AT_original_df)\n",
    "else:\n",
    "    print(\"\\nSkipping complete pipeline run due to test failure.\")\n",
    "    print(\"Increase test sample size or check data quality first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
